{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition for House Prices: Advanced Regression Techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df_test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities      ...       ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0         Lvl    AllPub      ...               120        0    NaN  MnPrv   \n",
       "1         Lvl    AllPub      ...                 0        0    NaN    NaN   \n",
       "2         Lvl    AllPub      ...                 0        0    NaN  MnPrv   \n",
       "3         Lvl    AllPub      ...                 0        0    NaN    NaN   \n",
       "4         HLS    AllPub      ...               144        0    NaN    NaN   \n",
       "\n",
       "  MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         NaN       0      6    2010        WD         Normal  \n",
       "1        Gar2   12500      6    2010        WD         Normal  \n",
       "2         NaN       0      3    2010        WD         Normal  \n",
       "3         NaN       0      6    2010        WD         Normal  \n",
       "4         NaN       0      1    2010        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pave    1454\n",
       "Grvl       6\n",
       "Name: Street, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Street'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000   \n",
       "\n",
       "           ...         WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count      ...        1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean       ...          94.244521    46.660274      21.954110     3.409589   \n",
       "std        ...         125.338794    66.256028      61.119149    29.317331   \n",
       "min        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "25%        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "50%        ...           0.000000    25.000000       0.000000     0.000000   \n",
       "75%        ...         168.000000    68.000000       0.000000     0.000000   \n",
       "max        ...         857.000000   547.000000     552.000000   508.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean     15.060959     2.758904     43.489041     6.321918  2007.815753   \n",
       "std      55.757415    40.177307    496.123024     2.703626     1.328095   \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000   \n",
       "25%       0.000000     0.000000      0.000000     5.000000  2007.000000   \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000   \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000   \n",
       "max     480.000000   738.000000  15500.000000    12.000000  2010.000000   \n",
       "\n",
       "           SalePrice  \n",
       "count    1460.000000  \n",
       "mean   180921.195890  \n",
       "std     79442.502883  \n",
       "min     34900.000000  \n",
       "25%    129975.000000  \n",
       "50%    163000.000000  \n",
       "75%    214000.000000  \n",
       "max    755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28796de6898>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage       259\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1369\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           0\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "MasVnrType          8\n",
       "MasVnrArea          8\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "                 ... \n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         0\n",
       "TotRmsAbvGrd        0\n",
       "Functional          0\n",
       "Fireplaces          0\n",
       "FireplaceQu       690\n",
       "GarageType         81\n",
       "GarageYrBlt        81\n",
       "GarageFinish       81\n",
       "GarageCars          0\n",
       "GarageArea          0\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1453\n",
       "Fence            1179\n",
       "MiscFeature      1406\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice           0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley','Id'],axis=1,inplace=True)\n",
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)\n",
    "df_test.drop(['Alley','Id'],axis=1,inplace=True)\n",
    "df_test.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 75)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Utilities']=df['Utilities'].fillna(df['Utilities'].mode()[0])\n",
    "df['Exterior1st']=df['Exterior1st'].fillna(df['Exterior1st'].mode()[0])\n",
    "df['Exterior2nd']=df['Exterior2nd'].fillna(df['Exterior2nd'].mode()[0])\n",
    "df['BsmtFinType1']=df['BsmtFinType1'].fillna(df['BsmtFinType1'].mode()[0])\n",
    "df['BsmtFinSF1']=df['BsmtFinSF1'].fillna(df['BsmtFinSF1'].mean())\n",
    "df['BsmtFinSF2']=df['BsmtFinSF2'].fillna(df['BsmtFinSF2'].mean())\n",
    "df['TotalBsmtSF']=df['TotalBsmtSF'].fillna(df['TotalBsmtSF'].mean())\n",
    "df['BsmtFullBath']=df['BsmtFullBath'].fillna(df['BsmtFullBath'].mode()[0])\n",
    "df['BsmtHalfBath']=df['BsmtHalfBath'].fillna(df['BsmtHalfBath'].mode()[0])\n",
    "df['KitchenQual']=df['KitchenQual'].fillna(df['KitchenQual'].mode()[0])\n",
    "df['Functional']=df['Functional'].fillna(df['Functional'].mode()[0])\n",
    "df['SaleType']=df['SaleType'].fillna(df['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())\n",
    "df['MSZoning']=df['MSZoning'].fillna(df['MSZoning'].mode()[0])\n",
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])\n",
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])\n",
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])\n",
    "df['GarageYrBlt']=df['GarageYrBlt'].fillna(df['GarageYrBlt'].mode()[0])\n",
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])\n",
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])\n",
    "\n",
    "df_test['LotFrontage']=df_test['LotFrontage'].fillna(df_test['LotFrontage'].mean())\n",
    "df_test['MSZoning']=df_test['MSZoning'].fillna(df_test['MSZoning'].mode()[0])\n",
    "df_test['BsmtCond']=df_test['BsmtCond'].fillna(df_test['BsmtCond'].mode()[0])\n",
    "df_test['BsmtQual']=df_test['BsmtQual'].fillna(df_test['BsmtQual'].mode()[0])\n",
    "df_test['FireplaceQu']=df_test['FireplaceQu'].fillna(df_test['FireplaceQu'].mode()[0])\n",
    "df_test['GarageType']=df_test['GarageType'].fillna(df_test['GarageType'].mode()[0])\n",
    "df_test['GarageFinish']=df_test['GarageFinish'].fillna(df_test['GarageFinish'].mode()[0])\n",
    "df_test['MasVnrType']=df_test['MasVnrType'].fillna(df_test['MasVnrType'].mode()[0])\n",
    "df_test['MasVnrArea']=df_test['MasVnrArea'].fillna(df_test['MasVnrArea'].mode()[0])\n",
    "df_test['GarageQual']=df_test['GarageQual'].fillna(df_test['GarageQual'].mode()[0])\n",
    "df_test['GarageCond']=df_test['GarageCond'].fillna(df_test['GarageCond'].mode()[0])\n",
    "df_test['GarageYrBlt']=df_test['GarageYrBlt'].fillna(df_test['GarageYrBlt'].mode()[0])\n",
    "df_test['BsmtFinType2']=df_test['BsmtFinType2'].fillna(df_test['BsmtFinType2'].mode()[0])\n",
    "df_test['BsmtExposure']=df_test['BsmtExposure'].fillna(df_test['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Utilities']=df_test['Utilities'].fillna(df_test['Utilities'].mode()[0])\n",
    "df_test['Exterior1st']=df_test['Exterior1st'].fillna(df_test['Exterior1st'].mode()[0])\n",
    "df_test['Exterior2nd']=df_test['Exterior2nd'].fillna(df_test['Exterior2nd'].mode()[0])\n",
    "df_test['BsmtFinType1']=df_test['BsmtFinType1'].fillna(df_test['BsmtFinType1'].mode()[0])\n",
    "df_test['BsmtFinSF1']=df_test['BsmtFinSF1'].fillna(df_test['BsmtFinSF1'].mean())\n",
    "df_test['BsmtFinSF2']=df_test['BsmtFinSF2'].fillna(df_test['BsmtFinSF2'].mean())\n",
    "df_test['TotalBsmtSF']=df_test['TotalBsmtSF'].fillna(df_test['TotalBsmtSF'].mean())\n",
    "df_test['BsmtFullBath']=df_test['BsmtFullBath'].fillna(df_test['BsmtFullBath'].mode()[0])\n",
    "df_test['BsmtHalfBath']=df_test['BsmtHalfBath'].fillna(df_test['BsmtHalfBath'].mode()[0])\n",
    "df_test['KitchenQual']=df_test['KitchenQual'].fillna(df_test['KitchenQual'].mode()[0])\n",
    "df_test['Functional']=df_test['Functional'].fillna(df_test['Functional'].mode()[0])\n",
    "df_test['SaleType']=df_test['SaleType'].fillna(df_test['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28796b745f8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28795728ba8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAE/CAYAAACNR5LeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXe8HVXVv59vEkIJVYpgAiRAaCJNmiAdFH0hgNQAUkQQX2lWQF9FQRREsQLKjyrSe0A6UiyAtBBKQGJooYhIEUEIyV2/P9ae3LlzZ86de8+5Neu5n/ncmT1r9uyZc86ePWuvIjMjCIIgGBwM6+8GBEEQBPWJTjsIgmAQEZ12EATBICI67SAIgkFEdNpBEASDiOi0gyAIBhF93mlL2k7Sk5KmSTq6r88fBEHQF0g6W9Irkh6t2C9Jv0h94RRJ69apt087bUnDgVOBTwGrAxMlrd6XbQiCIOgjzgW2a7D/U8D4tBwMnF6n0r4eaW8ATDOz6WY2E7gY2LGP2xAEQdDrmNldwGsNRHYEfmvOPcCikpbpqt4RrWpgTUYDz+e2ZwAbFoUkHYw/edDwRT46bNiovmldEASDllkzX1Czdbz/6vTaLuIjl1zxC6R+KnGGmZ3RjdOV9YejgZcaHdTXnXbZTe10k9KFnwEwYuTo8LMPgmDAke+nekit/rBIX3faM4Blc9tjgBf7uA1BEATltM3uy7P1qD/sa532fcB4SeMkjQT2BCb1cRuCIAjKmT2r/tI8k4B9kxXJRsCbZtZQNQJ9PNI2s1mSDgVuAoYDZ5vZY33ZhiAIgirM2lpWl6SLgC2AJSTNAI4F5vHz2K+B64FPA9OAd4ADatU70EOzhk47CII6tGIicuaMR+pPRI75SNPn6wl9rdMOgiAYuLRwpN1b9FqnLWlR4ExgDXxG9HPAkcAqSWRR4A0zW7u32hAEQdAt+nYiskf05kj758CNZrZrmnRcwMz2yHZK+gnwZi+ePwiCoHvMrSNtSQsDmwH7AyTvx5m5/QJ2B7bqjfMHQRD0BGuNVUiv0lsmfysA/wTOkfSQpDMl5d0aNwX+YWZPlR0s6WBJ90u6v63t7V5qYhAEQYG2tvpLP9FbnfYIYF3gdDNbB3gbyEf0mwhcVHWwmZ1hZuuZ2Xrhwh4EQZ9hbfWXfqK3dNozgBlmdm/avpzUaUsaAXwG+GgvnTsIgqBnDIKJyF4ZaZvZy8DzkjJLka2Bx9P6NsATZjajN84dBEHQY+bikTbAYcAFyXJkOu3ePnvSQDUSBEHQbwyCiche67TNbDKwXkn5/r11ziAIgqboxwnGuoRHZBAEQcJsiOu0y3KgSTo+5TubLOlmSR8qHLO+pNmSdm3m3EEQBC1nEOi0m52IPJfOOdBONrM1k3v6dcB3sh0pR+RJeJS/IAiCgcVQt9Muy4FmZv/ObY6iYyaGw4ArgFeaOW8QBEGvMAhG2r3lxn4CsC8eW2TLVDYa2Bl3XV+/i+PzOSIJB5sgCPqE2e/3dwu6pLfstL9lZssCFwCHpuKfAUdZDU1/eEQGQdAvDAL1SG9bj1wI/B7P2LAecLHHimIJ4NOSZpnZ1b3chiAIgnrMjVH+JI3PBYKaADwBYGbjcjLnAtdFhx0EwYBiqNtpV+RA+3RyX28DngUOabaRQRAEfcJQ77TNbGJJ8Vk1jtu/mfMGQRD0BoPBuSY8IoMgCDIGQeyRHluPSFpW0u2Spkp6TNIRqfwDkm6R9FT6v1gqX1XS3ZLek/S1Vl1AEARByxgE1iPNmPzNAr5qZqsBGwFfkrQ6Hjf7NjMbD9xGe/KD14DDgR83cc4gCILeYxA41/S40zazl8zswbT+FjAVGA3sCJyXxM4Ddkoyr5jZfcDAt14PgmDuZBCMtFui05Y0FlgHuBf4oJm9BN6xS1qqB/WFR2QQBH3P3GCnLWlBPJ7IkWb27+Q80xRmdgZwBsCIkaOtC/EgCILWMGvgT0Q2a6c9D95hX2BmV6bif0haJo2ylyGCQwVBMFgYBCPtZqxHhNtkTzWzU3K7JgH7pfX9gGt63rwgCII+ZIjrtDcBPgs8ImlyKvsmcCJwqaQDgeeA3QAkLQ3cDywMtEk6Eli9EMo1CIKg/xgEI+0ed9pm9iegSoG9dYn8y8CYnp4vCIKg1xnqbuxBEARDikEw0m65R2Tad5ikJ1P5j1LZPJLOk/RIOuaYVlxAEARBy5g1q/7STzQz0s48Ih+UtBDwgKRbgA/iDjZrmtl7OTvt3YB5zewjkhYAHpd0kZk908wFBEEQtAwb+BbGzei0XwIyJ5q3JGUekQcBJ5rZe2lfZvJnwChJI4D5gZlATEIGQTBwGAQ67ZakGyt4RK4MbCrpXkl3SsryQV4OvI139M8BPzaz10qqQ9LBku6XdH9b29utaGIQBEHXDAKTv6Y77aJHJD56XwwPIvV13PxPwAbAbOBDwDjgq5JWKKszckQGQdAvtDhglKTt0vzeNElHl+xfLs0NPiRpiqRPd1VnU512hUfkDOBKc/6KZ7BZAtgLuNHM3k8qkz/jeSODIAgGBrNn11+6QNJw4FTgU8DqwMQUCTXP/wGXmtk6wJ7AaV3V2xsekVcDWyWZlYGRwKu4SmQrOaPwkfgTPT1/EARBy2mtemQDYJqZTTezmcDFuJFGHsMdDgEWAV7sqtLe8Ig8Gzhb0qP4ZON+ZmaSTgXOAR7FnXLOMbMpTZw/CIKgtXRDV52PRpo4IwW7yxgNPJ/bngFsWKjmu8DNkg4DRgHbdHXe3vKI3KdE/j8kl/YgCIIBSTeca/LRSCso6x+LNoUTgXPN7CeSPgacL2kNs+qGhEdkEARBwtpaaqc9A1g2tz2GzuqPA4HtAMzsbknz4XOAldFRm9Fpzyfpr5IeTp6P30vlZ6WyKZIuT9YlSNpf0j8lTU7L53t67iAIgl6htTrt+4DxksZJGolPNE4qyDxHitUkaTVgPuCfjSptZqT9HrCVmf0nWZH8SdINwJezyH2STgEOxSP/AVxiZoc2cc4gCILeo4ZVSF3MbJakQ4GbgOHA2Wb2mKTjgPvNbBLwVeD/SfoyrjrZ36yxW2YzOm0D/pM250mL5Tps4Z6PA98vNAiCAFruNGNm1wPXF8q+k1t/HDfqqE2zdtrDk+XIK8AtZnZvKj8HeBlYFfhl7pBdcmqTZTvXOKfe8IgMgqDvGeoekWY228zWxhXsG0haI5UfgHs+TgX2SOLXAmPNbE3gVtoztpfVGx6RQRD0PWb1l36iJbFHzOwN4A7SLGgqmw1cAuyStv+VBZEC/h/w0VacOwiCoGUM5ZG2pCUlLZrW58eNwp+UtFIqE7ADyesxJfnNmICPwoMgCAYObVZ/6SeasR5ZBjgv+dcPAy4Ffg/8UdLCuGH5w8AXk/zhkibgcbhfA/Zv4txBEAStp4XWI71FM9YjU/BwrEVKZ0LN7BggstUEQTBgsUEQTzs8IoMgCDL6Ue1Rl1bE0x6eYsFel7bHpQQIT0m6JHkCIekrkh5PJn+3SVq+2XMHQRC0lBbH0+4NWmE9cgQdJxVPAn5qZuOB13HfeoCHgPWSyd/lwI9acO4gCILWMQgmIpt1rhkD/A9wZtoWHkv78iRyHrATgJndbmbvpPJ7cNvuIAiCgcOs2fWXfqJZnfbPgG8AC6XtxYE3zCzLLz8Djylb5EDghqpK83FqNXwRwsEmCII+oR/VHnXpcactaXvgFTN7QNIWWXGJaIf3CEn74GnGNq+qOx+ndsTI0QN/ZiAIgqHBIJiIbDZzzYSUiHI+PGXOz4BFJY1Io+0O8WMlbQN8C9g85x0ZBEEwIBgMJn891mmb2TFmNsbMxuJxYv9gZnsDtwO7JrH9gGsAJK0D/AaYkBL7BkEQDCyG+kRkBUcBX5E0Dddxn5XKTwYWBC5LSRCKwcCDIAj6l0HQabfEucbM7sADRmFm0/EsxEWZLhNWBkEQ9CtD2Y09CIJgqNHiHJG9Qm94RErSCZL+JmmqpMNT+WKSrkoekX/NYm8HQRAMGOYS9UjmEblw2t4fz0C8qpm1SVoqlX8TmGxmO0taFTiVlNAyCIJgQDCUrUegs0dk4ovAcWZupZ6zFFkduC2VPQGMlfTBZs4fBEHQUgbBSLtZ9UjmEZl/PK0I7JFyPN4gaXwqfxj4DICkDYDlqXBljxyRQRD0C0O50857RBZ2zQu8a2br4WnFzk7lJwKLpUTAh+EBpGZRQuSIDIKgP7DZbbWX/qKlHpGSfofHG7kiyVwFnANgZv8GDoA5gaWeTksQBMHAYChbj1R4RO4DXI1H+gOPL/I3AEmLZrG1gc8Dd6WOPAiCYEBgbVZ76S96w077ROACSV8G/oN30ACrAb+VNBt4nPY420EQBAODQTDS7g2PyDdwi5KizN3A+GJ5EATBgGHgW/yFR2QQBEGGzRr4vXZTnbakZ4C3gNnALDNbT9LxwI74M+sVYH8zezHJb4GbCc4DvGpmlTG1gyAI+pyB32e3ZKS9pZm9mts+2cy+DZBc2L8DHCJpUeA0YDszey7nKRkEQTAgGAyxR1quHilYhIyiPXPNXsCVZvZckouY2kEQDCwGwUi7WY9IA26W9EDK6whAChj1PLA3PtIGWBl3rrkjye9bVWl4RAZB0B8MBpO/ZjvtTcxsXeBTwJckbQZgZt8ys2WBC4BDk+wI4KO4ZckngW9LWrms0vCIDIKgX2jrxtJPNNVpZxOMSdVxFZ2TH1wI7JLWZwA3mtnbSQd+F7BWM+cPgiBoJTar/tJfNBN7ZJSkhbJ14BPAo7kAUQATgCfS+jXAppJGSFoA2BAP6RoEQTAgsLb6S3/RzETkB4GrPIwII4ALzexGSVdIWgV/gXgWOATAzKZKuhGYkvadaWaPNtX6IAiCVtLizljSdsDPgeF4n3diiczuwHfxOcKHzWyvhnWaDWwTlxEjRw/sBgZBMCCYNfMFNVvHP7fdvHZ/s+QtdzY8n6TheOylbXH18H3ARDN7PCczHrgU2MrMXpe0VFeWdb2RjT0IgmBQ0mL1yAbANDObbmYzgYtxx8M8BwGnmtnrUM8UutnMNYtKulzSEykf5MckfUDSLZKeSv8XS7I7pvyQk5M538ebOXcQBEGr6U6nnTdNTsvBhepGA8/ntmeksjwrAytL+rOke5I6pSHNOtf8HLcI2TWFXV0AzwV5m5mdKOlo4GjgKDzV2CQzM0lr4q8EqzZ5/iAIgpZhs+trWMzsDOCMBiJllRXVLyPwQHpb4Jm8/ihpjRR4r5RmrEcWBjYDzgIws5npRDsC5yWx84Cd0v7/WLsCPe8pGQRBMCCwNtVeajADT3KeMQZ4sUTmGjN738yeBp6ki2iozahHVgD+CZwj6SFJZybTvw+a2UsA6f+cGCOSdpb0BPB74HNVFYdHZBAE/UGLddr3AeMljUuaiD2BSQWZq4EtASQtgatLpjeqtJlOewSwLnC6ma0DvI2rQioxs6vMbFV89H18A7nwiAyCoM8xU+2l67psFu4RfhPuk3KpmT0m6ThJE5LYTcC/JD0O3A583cz+1ajeHpv8SVoauCelG0PSpninvRKwhZm9JGkZ4A4zW6Xk+KeB9QsRAjsRJn9BENShFSZ/MzbcqnZ/M+bePzR9vp7QTI7Il4HnkyMNwNZ4GrFJwH6pbD/cExJJK6WEvkhaFxgJNHyiBEEQ9CVts1V76S+atR45DM8HORLXwxyAPwgulXQg8BywW5LdBdhX0vvAf4E9rKfD/CAIgl6g5gRjvxIekUEQDAlaoR55Zu1ta/c3Yyff0i89fOSIDIIgSAzwMSzQOx6RlySvx8mSnpE0OSd/jKRpkp6U9Mnmmx8EQdA6Wmyn3Su03CPSzPbIdkr6CfBmWl8dt1P8MPAh4FZJK5vZ7CbbEARB0BLqmPL1Nz3utHMekfuDe0QCM3P7BewObJWKdgQuNrP3gKclTcMDqtzd0zYEQRC0ktn9aBVSl97wiMzYFPiHmT2VtusETwHCIzIIgv6hlc41vUVvekROBC7KbdcJnuKF4REZBEE/MBh02s102jOAGWZ2b9q+HO/EkTQC+AxwSUG+q+ApQRAE/YZZ/aW/6A2PSIBtgCfMbEbukEnAnpLmlTQOj2T1156ePwiCoNUMhpF2b3hEgluJ5FUjpEApl+Id+yzgS2E5EgTBQGJ228BP5hUekUEQDAla4RE5ZewOtfubNZ+5NjwigyAI+pO2IW6nvQodJxpXAL4DLI7bZLcBrwD7m9mLkr4O7J0772rAkmb2Wk/bEARB0EoGg3NNS9QjKVX8C8CGwOtm9u9UfjiwupkdUpDfAfiymW3VqbICoR4JgqAOrVCPPLjsjrX7m3Wfv2ZQq0e2Bv5uZs8WyqtyQRZtuIMgCPqdIa0eKdDBWkTSCcC+eNyRLfOCkhYAtsPT8JSSUtEfDKDhixAONkEQ9AWDwXqk6RYmc78JwGVZmZl9y8yWBS6gc+e8A/DnRrrs8IgMgqA/sG4s/UUrHiufAh40s3+U7LsQz1iTp5MNdxAEwUCgzVR76S9a0Wl30E9LGp/bNwF4IrdvEWBzUt7IIAiCgcRgCBjVlE476ae3Bb6QKz4xmQO2Ac8CecuRnYGbzSxC9wVBMOBo6+8G1KCpTtvM3sHtsvNlRXVIft+5wLnNnDMIgqC3sNJgpAOL8IgMgiBIzBoEJn/N5oj8sqTHJD0q6SJJ80kaJ+leSU+lfJEjC8fsKskkrddc04MgCFqLodpLf9HjTlvSaOBwYD0zWwMYjluGnAT81MzGA68DB+aOWSgdc2/nGoMgCPqXtm4s/UWz1iMjgPlT0oMFgJfwnJCXp/3nATvl5I8HfgS82+R5gyAIWs6QHmmb2QvAj4Hn8M76TeAB4A0zm5XE5uSBlLQOsKyZXddV3ZEjMgiC/mBIj7QlLYZH8xsHfAiPM/KpElGTNAz4KfDVOnWHR2QQBP3BbFR76S+asR7ZBnjazP4JIOlKYGNgUUkj0mg7ywO5ELAGcIckgKWBSZImmNn9zVxAEARBq+jHLGK1aUan/RywkaQF5D1xliPydmDXJLMfcI2ZvWlmS5jZWDMbC9wDRIcdBMGAog3VXvqLZnTa9+ITjg8Cj6S6zgCOAr4iaRrueHNWC9oZBEHQ6wyGgFHNekQeCxxbKJ4ObNDFcVs0c94gCILeYMi7sQdBEAwl2jTwldq94RH5R0mT0/KipKuT7KqS7pb0nqSvtab5QRAErWN2N5b+ouUekWa2qZmtbWZrA3cDV6ZDXkvyP26yzUEQBL1Cm+ovdZC0naQnJU2TdHQDudrhPVrtEflirhEL4d6RVwOY2Stmdh/wfpPnDIIg6BVaaT2SEp6fivuvrA5MlLR6iVy3wnu01CPSzG7OiewM3JZlZu8O4REZBEF/0GLrkQ2AaWY23cxmAhfjDolFuhXeo6UekZL2yYn0OON6eEQGQdAfdEc9kh9cpuXgQnWjgedz23PCemR0J7xHRm94RP5O0uL4U2bnJuoPgiDoU7pj8mdmZ+C+KVWU6VDmDNJz4T3278Zpm+q053hEAv/FPSIzD8fdgOvMLKL5BUEwaJjdWou/GcCyue0srEdGj8J79LjTNrN7JWUekbOAh2h/6uwJnJiXl7Q03qkvDLRJOhJYvSc67yAIgt6gxc419wHjJY0DXsD7xb2ynWb2JrBEti3pDuBrXYX36A2PyFKPRzN7GX/SBEEQDEha2Wmb2SxJhwI34SbRZ5vZY5KOA+43s0k9qTc8IoMgCBKtThFpZtcD1xfKvlMhu0WdOpv1iDwieUM+ltQdSDpe0pTkEXmzpA+l8kUkXSvp4SR/QDPnDoIgaDVDPQnCGsBBuJXIWsD2ksYDJ5vZmskj8joge6p8CXjczNYCtgB+Ukz6GwRB0J8MaTd2YDXgHjN7JyU8uBPYuTCxOIp2ExcDFkqxtxfE3dpnEQRBMEBotRt7b9CMTvtR4IRkk/1f4NMkkz9JJwD74nkjt0zyvwIm0Z7JZg8zK33LSEbqBwNo+CKEg00QBH3BYAjN2owb+1TgJOAW4EbgYdLI2cy+ZWbLAhcAh6ZDPglMxr0n1wZ+JWnhirrDIzIIgj5nSOu0AczsLDNb18w2w9UdTxVELgR2SesHAFeaMw14Gli1mfMHQRC0ksGQuaZZ65Gl0v/lgM8AF6XJyIwJwBNp/TncaxJJHwRWwbPcBEEQDAiGuk4b4Iqk034f+JKZvS7pTEmr4G8QzwKHJNnjgXMlPYL75B9lZq82ef4gCIKW0Z9WIXVp1iNy05KyXSpkXwQ+0cz5giAIepO2flV81CM8IoMgCBJDwnpE0tmSXpH0aK7sA5JukfRU+r9YKpekX6TUOlMkrZs7ZnYud2SPfO6DIAh6k6EyEXkusF2h7Gg8K8144La0DZ5WZ3xaDgZOzx3z3yx3pJlNaKrVQRAEvcCQMPkzs7twc748OwLnpfXzgJ1y5b9NZn33AItKWqZVjQ2CIOhNBoP1SE9N/j5oZi8BpP9LpfJG6XXmSyl57pG0Ew2IHJFBEPQHs7HaS3/R6onIRul1ljOzFyWtAPxB0iNm9veySvJpfEaMHD3wp3ODIBgSDImJyAr+kak90v9XUnllep1k8oeZTQfuANbp4bmDIAh6hTas9tJf9LTTngTsl9b3A67Jle+brEg2At40s5ckLSZpXgBJSwCbAI830e4gCIKWMxisR7pUj0i6CI9/vYSkGXh6sROBSyUdiLun75bEr8ej/U0D3sHjjYCHcf2NpDb8QXGimUWnHQTBgGIwqEe67LTNbGLFrq1LZA1PdlAs/wvwkW63LgiCoA/pzwnGuoRHZBAEQWIwjLRb7RH59ZzX46PJC/IDkpaVdLukqSk/5BG9eVFBEAQ9wbrx11+01CPSzE7OvB6BY4A7zSxLK/ZVM1sN2Aj4kqTVW3QNQRAELWFu9IjMMxG4KNXxkpk9mNbfAqbS7nQTBEEwIBjKJn9VHpEASFoAH51fUTxQ0ljcRvveqsrDIzIIgv5gSJj89ZAdgD8n1cgcJC2Id+RHFrK2dyA8IoMg6A9mDQLrkVZ7RGbsSVKNZEiaB++wLzCzK3t43iAIgl5jqExEllHlEYmkRYDNC2UCzgKmmtkpPTxnEARBrzIkJiKTR+TdwCqSZiQvyBOBbSU9BWybtjN2Bm42s7wyehPgs8BWOZPAT7fsKoIgCFrAYBhpt9QjMsmfi5sJ5sv+RHkEwCAIggHDYHCuCY/IIAiCRJsNgYnICo/I3ZJnY5uk9XLlG+TUHw9L2jm374jkJfmYpCNbfylBEATNMRiSIPTUI/JR4DPAXSXl6yWPyO3wyH4jJK0BHARsAKwFbC9pfDMND4IgaDWDQafdI49IM5tqZk+WyL5jZrPS5ny026CvBtyT238nPmEZBEEwYBgS1iPdRdKGkh4DHgEOSZ30o8BmkhZP3pKfpmOGm2Id4REZBEGfM5Td2Csxs3vN7MPA+sAxkuYzs6nAScAtwI3Aw3gQqao6zjCz9cxsvWHDRrW6iUEQBKW0Wj0iaTtJT0qaJunokv1fkfS4pCmSbpO0fFd1trzTzkgd9dvAGmn7LDNb18w2w9UtT/XWuYMgCHrCbLPaS1dIGg6cCnwKWB2YWBLd9CF8HnBN4HLgR13V29JOW9I4SSPS+vLAKsAzaXup9H85fBLzoopqgiAI+oUWq0c2AKaZ2XQzmwlcjEdInYOZ3W5m76TNe/Bk6A3paY7I14BfAksCv5c02cw+CXwcOFrS+7iu/n/N7NVU1RWSFgfeB75kZq93de4gCIK+pDsTjJIOBg7OFZ2Rgt1ljAaez23PADZsUOWBwA1dnbcZj8irSmTPB86vqGfTrs4VBEHQn3THlC8fjbSCMi/w0hNI2gdYD4/b1JDwiAyCIEi02CpkBh2t5MYALxaFJG0DfAvY3Mze66rSnnpEnizpiTTjeZWkRXP7jkkzpU9K+mSufFFJl6fjpkr6WFfnDoIg6EvMrPZSg/uA8WmubyQesnpSXkDSOsBvgAlmVgxxXUpPPSJvAdZIM55/w/NBkmZG9wQ+nI45Lc2gAvwcuNHMVsW9IqfWaWAQBEFf0Uo39uSjcihwE97fXWpmj0k6TtKEJHYysCBwWQr/MamiujnU0WnflVKE5ctuzm3eA+ya1ncELk5D/KclTQM2SM42mwH7p+NnAjO7OncQBEFf0mqnGTO7Hri+UPad3Po23a2zFSZ/n6N9xrNstnQ0sALwT+AcSQ9JOlNSpddMeEQGQdAftFg90is01WlL+hbu2XhBVlQiZviIfl3gdDNbB3e66eQdNOeA8IgMgqAfGNJu7JL2A7YH9rb2x07VbOkMYIaZZRnYL8c78SAIggHDkIjyV4ak7YCj8BnPd3K7JgF7SppX0jhgPPBXM3sZeF7SKklua+DxJtodBEHQclrpxt5b9NQj8hhgXuAWz9nLPWZ2SJoZvRTvkGfhno+zU1WHARck05fpwAGtvpggCIJm6E+1R13Unwr1OowYOXpgNzAIggHBrJkvNJ2H9mOjt6zd39z9wu39kvc2PCKDIAgSA30QCy32iJS0dy5H5OSUQ3LttO/GlDfyMUm/zjndBEEQDAiGivXIudT0iDSzC8xs7ZQj8rPAM2Y2OR2zu5mthcfXXhLYrQXtD4IgaBlDwnqkIkfkzblckFUxYCeSi5ltZv9OqyOAkVREuwqCIOgvZltb7aW/aLVHZJ49KCQ6kHQT8ArwFm6rXUp4RAZB0B/MjR6RWfmGwDtm9mi+PCVKWAY3F9yqqt7wiAyCoD8YKjrtUio8IjP2pCKdmJm9izvh7Fi2PwiCoL8YDDrtHpn85TwiNy94RCJpGD7JuFmubEFgITN7KeWQ/DTwxx63OgiCoBdoGwQmfy31iEyHbIbHGZmeq2YUMEnSvMBw4A/Ar1t1EUEQBK2gP0fQdQmPyCAIhgSt8Ihcdan1a/c3T7xyX3hEBkEQ9CeDQT1SayKywivy+OQROVnSzZI+VDhmfUmzJe2aK9tP0lNp2a91lxEEQdA8g2Eisq71yLl09oo82czWTN6P1wFzUugkF/WT8NxoWdkHcH34hsAGwLGSFut504MgCFpLm1ntpb+o1WlXeEX+O7c5io4ejocBV+CONBmfBG4xs9fM7HXcFb74IAiCIOg3BsOEDr52AAAgAElEQVRIuymdtqQTgH2BN4EtU9loYGfceWb9nHhV/siyeg8GDgbQ8EUIB5sgCPqC2XPC/w9cmvKINLNvmdmyuEfkoan4Z8BRueQHGVX5I8vqDY/IIAj6nMHgxt4q65ELgd/jOuv1gIuT/fYSwKclzcJH1lvkjhkD3NGi8wdBEDTNYMhc0+NOW9J4M3sqbU4AngAws3E5mXOB68zs6jQR+YPc5OMnSCFdgyAIBgID3W8FanbaFV6Rn06JetuAZ4FDqmsAM3tN0vHAfanoODN7rdExQRAEfclgsNMOj8ggCIYErfCIXHrR1Wr3Ny+/MTU8IoMgCPqT/kxuUJce5YjM7fuaJJO0RNqWpF9Impa8JddN5VsWcke+K2mn1l9OEARBzxkM1iM9zRGJpGWBbYHncsWfAsan5WDgdAAzuz2XO3Ir4B3g5qZaHgRB0GKGhEdkmTdk4qfAN+hoa70j8Ftz7gEWlbRM4bhdgRuKcbiDIAj6m6Ey0u6EpAnAC2b2cGFXHa/Hyqw2ufojR2QQBH3OYEg31u2JSEkLAN/C7aw77S4pm3N1adT9EXKBpMowszOAMyCsR4Ig6DsGujUd9Mx6ZEVgHPBw8nocAzwoaQN8ZL1sTnYM8GJue3fgKjN7v2fNDYIg6D2GhPVIETN7xMyWMrOxZjYW76jXNbOX8YS9+yYrko2AN83spdzhE+lCNRIEQdBfDImJyOQNeTewiqQZkg5sIH49MB2YBvw/4H9z9YzFR+F3NtHeIAiCXmMwTESGR2QQBEOCVnhEzjvfsrX7m/fefb7L80naDvg5ntD8TDM7sbB/XuC3wEeBfwF7mNkzjepsKjRrEATBUKKVI+2UwetU3H9ldWCipNULYgcCr5vZSrgZ9Uld1RuddhAEQaLFOu0NgGlmNt3MZgIX474seXYEzkvrlwNbK1l4VNKdJ0t/LcDBg0U2zh+f1WA5/2Bqa3fq7KsF9/q+P7ccXNi/K64SybY/C/yqIPMoMCa3/XdgiYbn7e8Lr3lz7h8ssnH++KwGy/kHU1u7U+dAWYDdSjrtXxZkHivptBdvVG+oR4IgCHqHrvxWOshIGgEsQnnYkDlEpx0EQdA73AeMlzRO0kg8hMekgswkYL+0vivwB0tD7ioGSzztMwaRbJy/f8/fHdm5/fzdkR1M5x8QmNksSYfiYTuGA2eb2WOSjsPVPZOAs4DzJU3DR9h7dlXvgLfTDoIgCNoJ9UgQBMEgIjrtIAiCQUR02kEQBIOIwTIROdcgaeFG+83s3yXHHGFmP++qbDAg6QYz+1Ra/4aZ/agL+WHARmb2lz5p4ABE0jgze7qrssGApGuhOsOAmU3ow+YMSAbsRKSkTYDJZva2pH2AdYGfm9mzJbJLAkfh/v3zZeVmtlVBbhgwxczW6EY7lgfGm9mtkuYHRpjZWz26qHrnex7/0gr4EPBWWl8Qzxa0XMkxD5rZuoWyh8xsnRLZWvcqJz8aWJ7cA948BV1Rrsv7JGkU7u31bKH8w2b2WLHdZddV0ca7zexjXchsZJ4CrzbpO/hd2q9fgJnZCiWy8wK7AGPpeK+OS/sfobwzyupcs6TOFYEZZvaepC2ANfF0fm8U5Mo+/wfM7KO1L7asYZ7w5KvAcmZ2kKTxwCpmdl2JbO17leQXw3PJ5r+Dd0naPG1+Blga+F3angg8Y2bfbOaahgT97TXUwJtoCv7Br5XWjwDurJC9GQ+8MhXYHDgbOKlC9gL8S1inDQfhtpZ/T9vjgdty+z8C3IOnWDsDWCy376+59beAf5csbwH/rjj3acCE3PYOwMkFmYnAtcDruL1nttwB3NqCe3US8AwecvfatEzq7n1KZbsAL+Fuu4/gMdizfQ92td7F5/S9VL8ayOTrvbtmvU/gwX6WAhbPlgrZG4FL8LypX82W3P7lGy0VdU7GO8CVcE+5nwLX5/avmq7773gnly37A49V1LlR+qz+A8wEZjf4DmbX82janh8fSDV7rz6fvgOvA7cD/8Xtk/Myd5Uc16lsblz6vQGVDUs/MuA7wIH5shLZB9L/Kbmyqg7+D3hneRu5jq5CdjIwEngoV/ZIbv1PeKb6RYGv4S6pK6Z9DzW6vhrX38ltt1iWfvBb4PHON88t6+Ij3Wbv1ZPAvDXa2vA+5WRGp/WNU90TivcKeAO4Ergqtz5nqTj/W0Bb6oRKH4aFc9T6bIB7u/F5PdqLv4GvA4eVXMeOwDl4SM9zcssvgI2rvlf4Q+Ah3Hb4AOCERt/BwjkfbsG9egQfYU9O26sClxRkpgIr5LbHAVNbfY8H4zKQddpvSToG2AfYLIU5nKdCNktf9pKk/8FdRcdUyH6vG214z8xmZkG3kptp/hV3QTO7Ma3/WNIDwI2SPksDvZykpej4Wvhcidhrko7GXw8Nvw+v5wXM1QzPStoG+K+ZtUlaGf8RPFJx+u7cq+n4PX+v6loSXd0ngGFm9kJq918kbQVcJ2nZguwuufVfdXFeUn0L1RAbll7Jh+XW50RTM7M5rsOSMlXD7ZJOxh8Y7+VkHyyp/y+SPmJmVfc9q3sj4JfAaviDbjjwtpmVzWW8L2ki7jG3Qyqb8xsws2uAayR9zMzubnTePGY2TdJwM5sNnCOpaj5gZlJ1WWr7ihS+Cz28V++a2buSkDSvmT0haZWCzJeBOyRNT9tjgS/UvcahzEDutPcA9sJH2S9LWg44uUL2+5IWwV9JfwksjH/onTCz7mTOuVPSN4H5JW2LZ+K5NrdfkhYxszdT3bdL2gW4AvhAsbKUxf4nuK76FXykPBX4cMm598IfMDek7btwdUgZdwGbpo7oNnw0tQewd4ls7XsFvANMlnQbHX+IhxfkurpPAG/nJ8fM7IWkp70G169ndd+WPyg9AFYDXjSzfxX2rZp+8KV670KHsQjwAO0ddX6fAXnd608KVa1XkJ2j/8/pqkcAB6RO5j2qddW/wr3eLkv17ouPfMs4ADgEHwk/LWkc7TpeJP2S9g6103ej5HMCeCe5VE+W9CNcZTWq4vzfxdU+y0q6ANgEV73kqX2vcsyQtChwNXCLpNcpxOQwsxuTDn3VVPSEmXU1eJgrGMgTkaPwJ/Ls3OjxBmsyKbCkt2gf2Y3ERy6lI500cXkgnnleuDvqmZZumqS9gOlWmOBKD5hvm9lBhfKH8S/xrWa2jqQtgYlmdnCT1/Sgma0r6TBgfjP7UdVEZDfr3a+s3MzOK8g1vE9JZl3gLTN7qnDsSPwenJe2TwVOM3f3XRj4Cz4aXRQ4wswuzR17hpkdLOn28maWT67WRdIKZja9UVmagK3EOk+63m9m60maknXokv5iZhtXtGF+fA7myZJ9pZ9P7tznFctSe/+Bf/e/jD/MTjOzaRXnXxzXgwu4x8xebXTO7pImHhcBbkxva59pJG9mV7by/IOS/tbPVC34qGgBYDQ+0XcVcEGF7Mr4CDObMFkT+L+a59kJ+EGD/SNTfR8BRjZ5TZmO8GFcXQC5Ccu0fRUFPS5d63QfAj6GT4p+OJU9UiHbrXuVrn+NtMxTsn848Ltu3ocxwJZpfV5gVG7fY7n1I0jzDfjbSa2JySQ/T2F7eWCR3PaWeBqoL1d9rmXnI80JlJSfX7PsrnRPfwv8KJ2/Sk+8A677fzptr03F/Es37//8uBVIV3KT8Le7UTVkfwAsmtteDPh+A/mPAwek9SWBcWn9nAbL2c1e+1BY+r0BDT7UbBLmMOAbab1q5vpOPEtEfsKk9sQQPoIoK/8f/IFxRzrHc8CnSuRWxhMZ34xPdP6Bwmx4krsVN937JZ6V/ufAXwoyW6flF3gmi53Tcinww4p2bpZ+YEel7RWAXzR7r/BJzmfTMXcBTwOblcjdVNXxlch+DldNZJYmK5OzdCm06zpg/7J9FXULf5M5E/hHYd+9wIfS+trAq7iK6DxyMY/T/p5YZTxY2B4OPF4itzzeaS4MHAucAqxUUecD+Ci0aiJ8iVTH4el7dTpunXNNgzprPwjwSe3T0nfgMjwK3XwVsp0+m+I9yZUfi6vP/pa2PwT8ue7vdW5f+r0BlQ3r3ujxvuyYXFlVB5//Ee4KnEiFCRhuxrRSbntFXLdWlHsY+CLeGX40W0rkRqUf8wh8culwqs2i7ipsq1jWw/vanXv1ALkRGd7BdhppAr/Bzci+DXwlWyrq7Moi5w7cImdN3HpkmVQ+vOzep30b4g/A53BTtv3ImV8mmby1zI+BH6X1Yfl9qay2VQZwDG6tMouOppz/ouIh243P6t6Szyp/HTfjI9xfAo/jViar4iaYdzT4TIsPgildtGM4sC0+cKgyD5xCztIIfzBVPeAmp+9zZRtSG0+hPSvMT8i9Kc3Ny0CeiDwC/0FcZa7fXAG36Szj1TSz7b2btCs+wVLGDrn1WbgdcjFvW8Yr1lHXNx2fQCwyy8xOr6hjDmb2dm6zk76xwFKSxlp7Zubl8NfIWmT63pJd3blX81hOl2pmf5NUZsHzYlqGAV1ZcrxrHS1Nhhf2H4JP1i2N2zlnbdsGnxSbg6QTgN3xzvoiIAt5WXZv83n3tsK/W5hb3HQQtG5YZZjZD4EfSvqhmR3TSDa1+WlKLIus3Anl0TRvMjxNyh2O6/gzPmhm35RfwLNmlk3UPyHpSxVNmGVmbxavuUF758d/M3vgpqRV39vfAbdJOge/vs81kJ1pZiYp+w6WTYSejb817J62P4s/OBvqvOcGBuxEZHdIHfoZuP3v6/hr/N5W4j3ZzXpPx19nL8W/iLvhr5Z/hvZJEUnfxTvzq+hoZfFaob7uTIL+D/DrdD5wh5Uvmtn1OZlOFirZLlxP2smUrzv3StLZqb3np6K9cfvvAyrO2yWSfoJPhB2AW5l8CXiq2OGVdZgqeDVK+id+f34GXGduRja9rAOU9HNgGeBlvBNa2czel7QMcK2ZrVdyzHz4BOuH6Wii+bmKayv18ivILJ7bnA//Tn3AzL5TUt8CwLfwCV5wNdT3zezdtH+OJ6QKXpHF7Vz5WficxtG4Cuhw/OF8SInsJfhbzI34b+AOM2sru/Ykvx3+cBVws5ndVCH3Nfw+bQv8EO/gLzSzX+ZkJpvZ2oXjOpXNjQzYTlvubv0NOv9gylzTdzWzS9MTe5g1cDOXNAZ/ndwE75D+hFslzCiRPadBEy378abRU9n+UhfeXP07ARtYhWtuGuVk5nCP4yOU2bn9s3F9Y37YZGl7tJmNLNTX3Xs1L96pfjzVeRduaVC01b2d8tFjJ+uNNLI+mI6WJr8pdgZlnY4Krtmprk/gk2Vb4W9i2wDLmtmswrHCR4tLA5dZshmXtA6wVFkHI+kyXEW2Fz6K3xt38DiiRPbz+NvhGPz1fyNc7dalBYukP5nZx7uSKznuDfwzEbBpWidtf9zMFis5puGDoCC7HXBL/jtX0Y7hwE1mtk032r4tue+Amd1S2H838HUz+1Pa3gT4sXURrmBuYCB32jfjbrRfw1+Z9wP+aWZHlcjeZWab1az3FuBC2keP++AjzW1b0vBuIukeM9uoC5nN8I5jJzNbOlf+FLC1lTjnSHrezJYtKa99r+oiKR/jYj58BDfLzL5RIT8PPtIyfJQ9K7dvA3wu42t0tMtfGNjdSmJ0pOPmA7bHO/CP4270exVkutW5ZGaTmXleavdNFQ+jR4D18UnttSWtCnzPzPYoyOUfRMNwu+YvmtlaJXXeAuxmKdZIGslfbGafTNubN2q/FXwS0vWfaGZf7+K6tzKzP1SZ31mJ2Z2kScBnLfksNKi71mcgaS3cwmYRvGN/DZ+UfrjRcXMDA1mnvbiZnSWPVncn7sBR5RhzS3rlugSYozcuqicSS5pZfgR9rqQjyyqtOypPP+Yv4lYc4JNpv7GCTXnhR5D9YEufmqkj3AvvAJfEX2P/ryD2M9y0qsyjsio6Xpf3StKlZra7KoIcFTtOM3ugIPLnqs8qjd7OSG0WMEbSQWZ2cxIZhVtFjKCjDv8tXJVQShopXg5cLmkhSnSf5jb/7yjnENUF2ef3hqQ1cNXK2ArZOl5+0NEZJZtT2b1EDjy41pzgUGb2utybNtu+M3WC55nZPl1dTLr+OkGkNsctoHYo2We4+WmRd4FH0oMm/73q4OBT9zNInfNaSlEvrSS65dzKQO60u+NunekY85MvRkcvt4xX5VEDL0rbE/GZ/jLOwUflWWexTyorjspPx/XTp6Xtz6ayzxfkupwElfQ9/DX+H6mN6+O23GcVG2dmp0oaJmljK4QmzesHC9S5V9nr//YVdXSgoFsfhlvPLF0h/jNgGzP7Wzp2ZdxEbbXU7ttxl+hzrODYUnLer9RpX4FanUvijDS6/TZuUrlgWi+jSy+/dJ4tu9HWNknLZW9ScseYDg/R1AkuKWmkmc2sUedDaVR8GR2v/8rc+rFJlXaD5ZyZuuD3aalD5WcgaQfckiSbYzkS2EXSs/iAqUwVOVcxkNUj2wN/xNPLZ+7W3zNPhlnn+NIvsdxb8Vf4K7jhs/GHV6gYak2GSHq4+HpbVlaz3f/CA0+dgkd0m6mKybXcMV2GJu3inFX36qSiOqqiLLOIEP4weho4LtNHFmQ7qWcqytbFJ8vG0jHUaX6y7dhG12VmneLMqKaXZzOo4OWXK18Htw3P5inux00Pp0kaUaKHz95KsreWzYCDi/p3Sb/BLTsm0bETPKWkbWXzNHPmZwqy3VKlyb1bV06bTxbfNHNyZZ+BmdlvJU3B46O/k/qAU/CB1Tq4quiTddszZLEBYHfYqgWqnStyMpvUKUvlt+Kj6+Fp2YdCyNEk9yApul/aXoHOzhY74lYnr6XlZnyyCDp66s2Dj8gvBGbgI/uXSB6UFe3sMjRpD+9VmUdgQ5veGuc9De9c9sEn9q7G7aYn0DEU7RO4imM8bh+/Yv4e98F3aXNgzbS+O/6gP5Iuoh7iXrzr4Wq4fPkuwDT8TWdNPOTw5/BJy4+Vfa/ScUvgbzw74OqSMpljy5ZuXOv6FeXfxucWlsVj6XwAt3Qpk92CGo5YFccui086Qs47FDf7O6rR93FuXAbcSFu5IDhlWMlrrKQNcf3vzvgX60u4l9frJbJlVglV5lFlo/IjrHM8ia3xznU63hkuj7vo3p72/y/+A/0GProC/2F/H3cK+aaVT0QtgHdmE3HTq5vNbN8SubdwXfBsPDZxFqyozJSwy3sl6Yu4Od4KuFdgxkK451oH/amk3fBR5VuS/g8f9X3fSiK8STq/WJbDsuuT9Gcz26SBbL7OLk3zqvTzOdk1c7Kn4h3rfLhJ4YK42dvGwHAz2zsnOwF3unkNn3M4FVdtjcU7nCymyhT8ofRMoe1j8QfUKVZiRaQGZoSSdrf66otivavjgasmAm9aucljbasoeYTLvSzZ9Se110VWkYhB0hK42nEiHqriKjP7WrpPG+PByp4GdjGz+9Mxj5vZ6mX1zVX091OjuOBWIpVLQfYE4Cnc7vTzeOD1pyvq/Rj+avo8Oa89PJJZaeyHbrZ7XtpHUPMW9k2lZISS2vtf3Hqgq/oXJcUV72H7unOvFsE7nYvoGKy/apQ1Jf3/OK7S2pGK+Mrk4lN00d5P4J6Wu5FG4eRG4gXZy4Dj8QfMfvhbzM8LMss3Wgqyj6f/8+HzHcPTtugcJ/xhXCWwPu6NuUIqX4qOnp6dXNpz+56sKG+YLAB387+RXNzpLu7p8rjK6WHcM/JVYGyz3/38d6BRGf7Q3ze1eTo+KTujIPM5/I3kQXwgkJWvQ8XbyNy2DMSJyEuAhczsn/nCNGtenEE+GB8JnU67c0XVaGokPmIaQUevvX/j7uz5c9Ua7TcwjVpREtZxcqeTJYuZ/UvSs5bzppRUNiHWJWnEN8d6xTqnhKp9r8xn9d8khYJVe/zvBSUtaJ31/5kd7/8Ap5vZNXKHozIekPRX4BxrtxgpY2/8IbggnuAA/DMpm9NYycx2k7SjmZ0n6ULc/jjPMlY/3di74BYp6fOZnbZNUlFP22btk6pPW5o8NbNXJOV11O/nJxUz0uRiVcjRI2g3I9xSyYww22lm28tt/X+frvl02u9Vh++cPGb2IsDFuK3+U6m9z5SdWO4EtBftoVGn4g4wZRZZAPfLHXfyjlhFq6JXgL/ibyR/Svdz57yAmZ2dJijH4dZaGS/jDllzPQOx0/4F/iQumhVti4/kvpgrW5p254qfyZ085i+b1LF2s8FzrWtPyfu72J9R1zTq35LWsoKNqdwWtWj2lJm5jcdjmWRxqbenfUKqA5JOxH/cF6SiIyR93MyOzonVvle5enfAJ4K6iv/9QpoM2wY4Se6UM6ysznRdnwQOSmqIi3CTtb8X5D5q9XN51jHNOw1X29SZuF0qWaYot07aLoYSyCdXaFPH5Ar5e3AscKukH+CdmeGf2dF4zs4yujQjNLOrkxrjLlxFlD2IixZB/8Strz6YruEpKgYmklbDv9c34TGAlNr6zTRQeaLksC/iqrbDk/xdtFtTZXwTV8mcDlwo97jshJk9L+lqy6lWrD2cQdDfQ/3iQuPXyNIANGnffPiI+Qpcp3hhhdzK+Ix8w4h8JcctRsVEH3hYyaoy/GHzLK6K2QHvgL+Hm/x9vKLOm4CFc9sL4yZYZbJTyE1U4pOmlROG3bhXD+NqlIfS9pbAGSVyC5AmDdP2MsAnatzTLYAXaE//tkFu31nUCB+aZD+fPp/NaI8P84WCTO10Y1RM7FEywYfrXaen/8VlekE2cxh5AH/9Px9Yq0E7rsLVYt/FO8Fr6Jgjcl5cLTQV2L7GfVoEVz/cktr3ev6e5+Quxx2ZiuW7AFeUlK+Tvk+r1fy8VsC9Mh/B32qOwsMK5GVOpWKCdG5f+r0BJR9oZR64qn0UOs3UwR1QIdtlRD48L+WqaX1evGN/LXUG25TU2WXcZXykexzeUV6ZfmxLN7jWJ8iFO03tqIpyN4WcvhmfYCzTMQ4r/hjTvdqvot4u43/nZNcCDk1Lo45oUXxEdi/+RrU7bjGzETkde/pBv4ebPz6Ij/jK7nOna2rwuS+GP4Sy9YYWETW/r5kFUGnI0hb+LjbH9fr578STeJS/+XtQ31J42OO/AM8X9pXq2Mv2pd/K3/A3punAQd1sx0fw+CN/L5Q/jpuP/j19vx8p+07PjctAtB65Ezf/+WuhfH3gJ1ZiN1phEdIhTkVX5QWZx4A1zMwkHYyrFLbBR+nnmdkGSW5VXFXwIzwsZsbC6RrK0ojVQtJ3cAuPK1LRzvgM+/dLZCfiIWZvx19NNwOOMbOLS2S74/J/K54k4oe46dkr+Ohn44LcEXg40EwdtDM+Iu/k4CN3vb8QD2hftML5ppn9IK2vWNYm66xGqXVNkp7B9b1l4e3MchYRkn7RqC7LWTBl36cqC6SSdqyMm9GNpaP9eT6FWVUgsEz2tSS3upk9njtulHWMJNmoHXNkJS2f/ywaXUtxX/qtrG9uV704Pnm4fp02VNR/PW65VDXf0lQQuKHAQNRpfx24VNK5tE9kZLn09swL5jrNRQqTgQuTM5EqcG0ywWsUkW+mtT/NPonHe5gNTJXnLMxYBVd1LEpHvfZbeCeWtbPK3KwqjyBmdpykG/AO2IBDzOy+sgsys4sk3YHrHYWbmr1cJkv3XP53xF9fv4xPLC2Cvy0UORDYMNcJnIRniM9HbfuBuUnbKlYRKS7rsBOz8byQMyV9HJ+U/F3ZcXWuyczGVhxbRnECrRHvyx1WxpR19tbZRPUyPHrjmbRP4Jad36h4wJB01VmHLWnjVN+CwHJpruQLZva/xYOrZPGOMiOvx+9wOJ11+u+a2TupPf+Se1KWoo5RLrNry67TzE1Uz8VVl+fhjkdNpRccigy4kTbMsVb4Ep7iCjyu7qlm9kpBbkd8JDiBjlYFb+Edbacs03VsTyXdg+tJ/4G/gn7UkvuspCfMbNX8weoi7rK6mUcwd9waePQ2A/5oZo8V9ncnsW12TJfX313SQ2l9aw8ZOh+ebOEjOZlaI9Gc/GT8IbQcroP9Pa4G6+RaX/MzbXjusntVs51LkCZgcVVBsd5iPs0u3/R60IZ7cZ3yJEt5QSU9aiUTuXVk1Q1PU7VHGgQ6RRvEzCb04HpG4fdyO1zvn7eI6eTlObcxEEfapM75WLlb7Gr4h/ZGiVztYPW5Y8bVEDsSn4xZEvhprsP+NK5bJW1/w8x+BOylBtmwe/JKJ+lQfPRzFf5juFTSqWaWn5H/Cm7KV8yIDZRnwq5z/YURUeeKOzvtnAPcKylr6474RGKe4QXLimKdxZF+m3m8688APzOzX0h6qOxYfAKsQ2jR9ODIk92j+fA3t4dTW9bE9esfzx17LY2vf0Ju/VXgYklTrV4Eujpvevnr+ExqW/bgvrqiTc+rY2KDynCqXclaift/A4oJRH5c56A0wt80bd5lZlNyu9/H35jmxc1zK2N4z40MyE4b5nSQv8EnIgSMk/QFM7uhRPz51GHUiZHdZUQ+c3veVYvHmicguD5XNDX9b2gi2KATrPRcxDvjDczsP6mOH+CTRnM6bfNM5MPwxLx/btSGQns2prNO9be59YWS3HG4+dz5qa17U5KZxsxOSeqZrOM7wMyKHeyq+Gt/w1f+HLPknpafxd+mwCcsy/gLyZyvqsxSoCZJF+PxOx5J22vgOuY8tTqedPwcm36VZIMpUY/sl/7n50DKrh9JpwEr0R7c7BBJ25pZMSvN8+kztTTQOZz272aRLmW7o9O3QvjXOpTMgVwgz7T0S3m8lVPwN+d1M9VL0M6AVI+AqyFwM6ZpaXtF4PdF1UTaVztGtqQz8R9/9tr6WWC2mX0+J9MwelxfvKIllcN6lhIOyG2f78+rHHKytQNGyd3IV8RjXmQjLCvpXJB0r5lt2FVZKl8XHzm14a7uDxb2P5S9jtds5xr4m8ZfzOx3ksbhbtIn5GSWxl2gf4c7gmS95sLAryu+Ky3NiKKKAFQZRfVIN+ueMyGetofhXpYfLsgtgYdDmJM1Bh+0dIpeWfeqI20AABtYSURBVEc2d02b4MGtMnvq3XCrqC/nZGuHB8gdMwX4WG4OZBSeMGJNSX/E528eKx4XOAN2pE39/IzgmUfOyW2fq4oY2bjuNR/n4w+Siq+12WhyFVyvmunLdyCnr+vOa3QetXsYZnJl8bDPB+6RlLceqeoAbpa0C3Bl9gNvwHrA6jXkAGZL2hv3ojPciqbTa7fc0mU33NJFwDmSLrMSS5e6mNmj5CbHkorqhILYJ/EM6WPw0VnGW7gjRxlT04P7d/g17UPFqFQ18jl2t1OWx5P5CrBcelMaj0/OFj1YwedTlsNt/MEDK00pCiUVzd7F8jLqyFp7vJT9gS2zt1BJv8Y7+TzZHEM2+s97RFaNkkXH79HsVIaZbVp6RDCHATfSVrsVyLaU5Gc0s6+WHHMrPuucj5F9gJltXSL7IB7i8e9pewXg8rJJMnn2nF0speSSB9e/zMy2S9ubJ9HP4HbYmXXDROAZKwQAkrua/4SCh2Fx5JSTXx8fvWaZ2EutR9S9gFGX4aFou/Qwkwcz+jntaqc/A0da56BHU4F1chOR8+M21avlZPY3s3NrnHNF3EvwdTz29m9wVdY03Aa4bHJ1FzO7olheUf98dFSP3YW73pel2+pOPsclcSeR1WmcHu8SXE20r5mtke7V3WUjfbn56/q46zdp/W5SZ5gNCirUGW/ib2bXFOrsjuyT+Ig4MzFcDHep75TcQSUBvsrKUvlXcDVRfg7kXDP7WUnbggIDcaSdN537B+5UAO6G2ynnXeJzeDS+n9Ieja8qTsHX8SD7HSLyVcguB+TjTM8k5x6d6fMkHW8d7YSvldQhoWvieNyJ5FbzNFZbkuJ7VPAkPiEzIp1nzcKETdaOrjKg51kCeFwe/yM/EdbprSB1zlWZ6vM8g3dUWcc3Lx2jA5J12HI75a/j973MTvlc/OG7MD5B+A38Hm2K6/PLUrNdJ89aPrZQZyfzxNQ5/zQtDSlRL/xM0p8osRLBQwhcgsdfmZMer0RuRTPbI5u4NrP/qkwZ7pSdp4z58DmDy9L2LrhT0oGStjSzI3soeyKeNOH2tL057p1Zxih56IQsp+PG+ECiEzXnQIIKBlynbT3I9J3UCx06naQe6fTkNrPbsldSvNN+wgqJanOcD/w1TXIarqL4bYnckpJWsBQsKOlfi/asAO9bsmWVNMzMbpfbNHdCbnZ1MO5unL0OGe0jxLxsNkk4zsyOl7QsHiDpr0VZqn90ZW1YEp8wGkvHzrAYMP894LE0t2D4W9KfslFdQV+e2Sn/P8otHBayZCEjT0OWvT3dIOmHFU29Bh8tPkB18KXsmjbB70HxoVE2EViWz7HqAVk3Pd7MNLrO9NQrVrXZPJ3Y8nh4gFvTcSOsczLmlYCtLMWQkXQ6rsbYFvck7JGsmZ0j9xXI5jCOtmr7/wOBsyUtkq7tTdqzJJUxO8kZYR3SLQZcp50hd1go0yc2+iLk+Qq5TlueYkxmdn7qpKek8oMkvW1mF5ac6wRJN9L1iODLwB1p9A7eyX2hRO4NSQvir+QXSHoFd9UtYy885GbDTihxGv7F3wofzf+HFLshE5D0KzzGSHdm+6/BQ63eSgMTMvw196rc9h0NZGdZLqphCfkfcDGYVtWPe0ymsqrBWfjn9QCNrwk653N8mup8jnXT4x2Lu+8vK+kCXPW0f1mFkg7CH9wfwCePx+APvKLabzQ+qs3u1yjgQ+apyIrfn9qyaTCwDf49PE7ScpI2KBsMmOcJzXI6yhrkf1S79Ug2B/I7JeuRqmOCHDYAfOnLFvy1LVv2xu2mf9GN44vxFB7CR3FFuYUpxAkp7B+O66CXy5YKuXnx+Bud4mnnZEbhI7YR+Ovz4fgIrUz2SioylZTIPphdY67s4YLMEbg+9BncEWTtGvVOrnn+pUrKSoM94aPc/8WDSnWK/YHra7NYI9l6tv12RZ1nAB+p2dbSON8t+L5uj3uMroGHE3iA6vjfi+NqlO0bfca4hc/Iwuf6SIncgfgD5RxcvTQddw4bBZzchOzp+MN/atpeDHeaKmvrB/EH4g1pe3Uq4r/jA6ZRhd9FxBWpuQy4icgqkrnTrVaY2Gkg/5yZLZfbnmIl5keN9kk6DB8Z/YP2GW6rkG1o+yzPmn2TmW1Ts/0fxVNxTaGj7rlTlnG5l9vG+A9q3aTWuNlKTOzS6/aeaZkP1x9fbCkmdEH2+7jJ3fXFfQW5J4FvW8qiIumr+A+2U5YRdeG9qIqYIznBstgjj+Ov/U/j96rR53Qi/iC+ko739cGczLlmtn9a389amD8y1TmazuqZTnMgSuaVSuaS8hAKD1Zc1zJ4EDThQb06JRXurqySF6ty5pqqyH2a1CjnAN8ys7VSWx+ychPVLj1og2oGrHqkhPH4SHcOauy0Mn+hbB6VBNSRW4SMrDjnEfiIsSpbe1ZHqe0zOf23+evnO5IWsQavjjnOwyfLHqFrnd8vcPXEUpJOwN2US7OGm3tnnoTHvV4Hz8N3LN6RFTkCj6H8Hv76X2WVsgWeuXw3fMQ1Fe8Uys7f0COzrFOuwae6IZvpZ/PptYreo/lO6QiqTS07ONeUYQX79zSHsQc++ZdP7lA2cX2npG/icc+3xd9Qri2RA58Efgl/EK8kaaWyB0E3Zd9Pg41M/74k1d/FJczsUknHAJjZLElV6qe8By2481TRgzaoYMB22rkOWen/yxSCxVv3rCbOAi6X9EVLJmtyk7ZTqf7CPE9nvWoZdW2f3wUeSRN2+cBGZdlqXrOaTjxmdoE8R9/W+P3aycyqbI/nwWM67Jnk7ySXDaVQb637a2YvJd3/MfiP+hhLnpy581Zl+cnquDLJvU5j79FOEfDM7Fl5UKnx5pNnS+IBkTpW4AHGvo+rSP6TKy92+t15/cx7w34PfwA2Yid8IFBnruJoXJ3xCD5Hcj0e7KkDkj6PP1zG4AOHjXBVWKe30u7IUj4Y+L+Ktr4tN5HMOviNqPjtWEfrERHWI91i0KhHWoGkQ/COJftB/wc40SomxuTpk1bBgxXlX6VPKcjVsn1Whfdc2eu3pJ/gOt1JhXN3MvmTdL6ZfbZRWRqpTcT1qPfiDjNXF988CnWUhjstjsrSQ+glXEc/Bh+932VmX8vJfM/Mjk0TzCVV+gRzGtlVYin1V+H8x+IPzlXMbGVJH8Lt6TfJyRyOO4BMBdbGvQCvSfuK4UZfwe+P8FFxhxC3FQ9ZVMPrM6kRdis+1Erkhv//9q4/6I6qPD8P0CRAJ0CngTBWG4bg8KuCaZhhoBNQlBHFQtpCqJNBKTC0Um3GSjrYtEQQqUAlVFKoP4BgS6ogpUD5WcKPQLVIICZg0USgoAIVFJISBFKe/vGczd279+y9u/fe77v7JeeZ2fn23vvu2XP323v2nPd93ueFZYDnd7MLtmvRKkt2cHg4fVbSvEFsg/2+aE0G7u4yGZgFqzoeCAu8TYPLmq3J2UyB6ZAz4QfR11RSNSmhHI2baQef68uZC4HmMh8PB9CWSnqjy+FdIekKAFcEBgfVSZ0q4pmwTUK5CwWoyH2W6xfuCAczf9Dj3Jl74ch8E4hQ/lAo/xV+8EUluc/Aqf6fVnmdvyLy+hhTQp9WoXNWtlQtIaOXg3//7LyBpHPC366UzuKgTGtL58WfYv7XuXD1lEdCGz8Nbq88TofVGv83rLCuJzlD0qVAhx5K/ntXLT0HdJmh59womwCsJnk32u+VtgdBcKdNIzmpwj3fsyxZP7YkLwXwDUlLe5wfkh6hk80yKu0P1Cmrugx2s62EXVr7weJsCTXQuEEbzoCcC+AVkgfDvN4L4NnR38OR7tpgRE+EuZyGmCtC1dXOFlfsw4dhMaJJAPYK3+/c4uAezt0znTf4DzOfZ1b0mHAS0FcK7WWCSXvTFMfXSR4Jq9xdIymmothW+5Lmf1+Ye72vpCfkOoWTsyV/8GfeVTi2VnCPps1dAs/cX4Kpaj9ERMgLQf+coVAxrWVRxPbZ7FbS0+G7Xx8mCW2Dtlpp3CdIui7/WfDb94Ns8F+FeHHiGJ4G8CDJm9DuTiveqz8muSscuL4ruJjKApF1bB8BsIhOiPoXeACPPsTCdbld0uMkFwGYRfJzas9g3T8LNoZVbCyPIKEX1AAKS35DjvoDD3AXhv3tMAAtCK0af9fCRU3/Nmw/BPDVkmOmAbgI9iV2rScJB+CODVsHBS7YrIJpYV0pXLlz/wNcOR0whepjJbYX1LgOq+GH9Uw4a/ES5OoO9jiW+f4iV/4LhVJgkdePln3WpZ/T0KpP+X5YBCpm++lwrZ6EZ9TfBvCJgs0KFGiO4TpcAwuGxdqNlTcrfq+NADaEbXNufyOADZHjd4YfINnr7QHs1OOebdt6XLcjUChLNqgtTMs8Ha7jua7EZk34+zvwTPo4FOiVve6RtFXbmjjTzs963ouwzJb0FkuzfXtDYdZM64nMUktPZDFaKb1FZKnJx6JLajLJE+HB/d7Q/y+RPEvS9QXTzZJeKXyPsiX11eH8WfB1XejL1RHbvLBW5h5ZpPhK4S15JjwX1qn+Ekt0qtnOjNgOXu3kxbVYsh97XTd4slnSz+jsUUq6KwTD8v2bCWAPSRcHn/0GeHl+G9oldAFXPmrzn8r+1JPpSvL5do8B8EEAb2O7VsfUSBt1guGAB773wfEUwCynO2HKZhtK/n9toKmwaxSKGKhL8lQd2wJmwiucGXDtxhgyt9aHYC2Xfw2/rTwOKqwIsxViN4nihAKaOGivIPlNOLC1GzxDyrilffuzc+iqJ1JA1dTkv4R5p/8T+joNziIsDtqP0RoZ29Op9J+EdVJi2F3StSTPAgC5IEAZheooWuXvVNi/fiXMConhTVr34qNo6byU6VTnl8KbASxXu263SvZjr7NyXESkNJc6g3uvBDfHAwCuCcHBIt1sCYKan6S74Ao3IDk7fLbFvaOItnrus6IW+U/h7/67aC89thHOphwEU5QLQso+9p3yBiSXSFrAEhVJtRdheIvk90i+Q3G1SPRjG/rxBVgM7Uew2/I8RdxoAT8JD7/3wXTSyfCDPn/+rkHmhGpo4qC9AI7Y7wlXus6CGdPhwXFQVNUTAaqnJm+n9lJoL6FwwwZ8Av4Or8NumjtgCloMr4YgXOanPQQeNDog6SMk58ER+U0A/jAyEGU4BV41nC/pKVonJVp7UQ6cToILGgMWsMqjbCAm7IPOo25w73iYIrkAniXvgpYMaIYZigtoPRyCjX1BrkDzPZLXavg1Cl8lOUvB10snUb1WsMnkTasWY9gT1n55CO2+75g0cB3bp2CVvxcr9OFEmEp6saSXwyTrrB7HJPSBxlP+aO7nHADPyPoGw2jzt9HSE7lfJRxRksfC/rm3w3SmqQAWS7q5YHcRHNDLxI3mwcvQvyjYvbvsXJFzz4ZlUQ+AXRJvg6liHceHWfsyeNDeD17CfkoDVv0IwbplcECM8HX4qALlj30UACgL7kXeywoBl75Hcr2kmSV9L/2sKsL//zy0shcHXsaHh+8/oxX82xPAScoF+KrOhHP2R8Tej7k/6tgG+93gxLa83Gw0aYftJcRWqlr5tYS6GLVTvbgBuAWu1gH4hn4OzgL7PqzlPIxzVNITKTl2QW5/JoDDw/7vwUL8l8CSmntHjr0HwBPwQHBAhXNNgrPzDkaXYFFo86iwTwB/DuDxEtt9YLfN9+HA3ZMAniyxXYWchgg84+7QaYEfJj3fC+/3DO51ea+op7Ic1tgu2p0KMx0GvU/Www9jDvH+ngy7ow4E8Fthf3LBJh/g/dawzt1HX0+DJwK/CPfuaygPxP8ZzM8+N2xrUQgGp21I/5dRdyDyz388t/8ZmI4GWBJzYFEZ2EXxIpxGvCbcXJXbhWf82f4tAN4VsZkN4OaS46fDvuwHw7kXVTzvexDEeCKfTY28t0+J7QNwssQaeAa5GE6uiNl2XJeS96qwLI6BVysvwJl22XY1rH+R2Z2BIA6FlljUI3AgdnmhzT3gmMC9aLGB7oPZI9OHcK/cA7u+hnl/V7lWj8b2u7R5KIDvwsHNN+CgYAdzpQ/btfAMe3V4vS9KHoZIIlDjtjXRp533IR6FwDeWtJHkMHR3K+mJdEGeFTFDNX2qsh7x39HC8gvhWfkWv3ZYvl4OrwRuhDnqy2CWQZE9sVDShZI2RFwMpyBecmtHWVOcsg7JYrou3zkR24cDnzZfQmqLi6oOywLVg3vfhBkWF8Bp3Fvs1B43gKQXABxGJ2AdGN7+N0krIt+lHywEcGsIPpdmxFYBW/Usd6Q1X/L1LHcqmHcL8MZwGSxLcB08YTgZXlENalsnaae0hFjCcNHEQftZWl3vx3A17dsBgM4kLGM51Gof1fREypD/EU0pteoUrALJ/WB/9x/AwcpvwK6MPJbAM/Fvw7PTh+CZcGygOAmtZJez0U5d/ADig/YvA/VrHck/BfATALuXfIc/gVO/Pwn/AO9Hrho8arAsVDG4J+kX8HL8BLq4bxZ7WImSGqGS7oFnxcPG+fCMdAq6Z8RWQZ16lhk1Lk+LA7r41CWtJ7m9nFF6FckyVlId2zqJOFchiUCNCxoXiKSL3p4L+7OXSrozvP8eOA25akS9rP2eeiLsoR4oKSv/tRz28bVlH5I8FcDRKug50BKqt8DL+e8qXpewTb+CLqywtyL/KLZLZhaPi+pghEDYfwHYFfat7wInMH0nZ1M3EPYr3Qbigm2l4B7JM+EHRpYefxx8P+QfGmMKkg9Lmt3bslabletZ1mjzfphq9zU4BvQcnIgVk1CtbFs47gj4XrldJWn1tP5IJgJVGuBPGAyNG7THGrS4UAdUPWU939YecHrvG2jNNGfDs7K5wRUCWlv483D5pWcQKHJo6Q+/mWvzSbTrMSzJv5Z0U852i9ARO0WP2l7X/F75dr8l6fd72FdmWZBcDwdt18YeRDm7NQAOU+A003ox/6ESTfSxAK29vSKbOAzY1nxJ/0hrjce417VdLrm2fxOOFUyCVzhT4QSX9f3YsoawU6CllkLVdW4SKqJx7hFaZ6EUivNJK6OfwblLW1V9qhfBgdS91MrEnArzcC+G/ewZHoSrfsdeC+26Fd2W0W2um5rXNe+L7KidGMESVBiIA54F8FgFO6I9vpHpeY8nzgSwkL31xKsg00PpkIxF/WxRAADJ4+BSa0vD6/tgV5dg99r6fmzRKey0P9rv0TxWoSWhnP8umaRylfsnoQYaN9Mm+TP4h70clhAtivnUqXEYa38aHGA6AO3c00oVcfo85zoA7ywOVHS6+ROS9om8f/wwl9F1rmu3GXxJ2/fAlMOegeLgnjkPZnl0uKdI7iCn2WdV2LNrMBdmjwzkHhsVSP6GSrIySX5YBe5/xTYfhDnez4bXq2Hph18FcJWko/q0XauWsNMOMLunr1VbwvARy9obNabDgZkD4eSS9wN4UdJ9gw7YAf8E85r3gkXrn4YpUGMJxWaWIRBU9v6wJSvrXNeDSG4Ivv13hf0NJDfmZvN5ZCyLs0l+KttK+nE+nLU5BV59ZFuGhwBA0oVwUdtNMD/4j8d7wCZ5OINiIMn5JL9I8h29jivB3TFGEclTkCtAXROTskE44AFJPw/xiKLSYR3bLSucMrdIESTn0pXYs9e7kjy+2tdIqAU1gHdYtsGJCB+DRZqGQtRHSA5Bu5rgfWP8PW4EcHLk/fkAbio5ZhE8cO8J+x2nIsLHbsJ1hQWPbkCrcss5KFGjA/Bwj7Z68pLHa4O5x4QTnNbALoK+7hWYGrkOOf48zPhZC7st+mlzfZfPfjSA7f+hXa1wM7ooF4ZjOopAN+l/uTVtjfNpAwAtNvMheHk8A07CuGFIzVfVExkmzgRwA8k/QssHeAhMC5xbcswZ4W+eEigU6mTWwRhe11+TdHRF238nebTKg3vTuszSoQECdn1gsyQFf/ClsnhY19T9Mki6NfjGbwsz0NPge2COTHPsB/9J8nR1spfOQKdWdWVb9SfsFFu1N3J8mehook97GbyEvw2uEv7YkNuvpCcyFiD5XtiXTjjz8+6xPmfu3GN2XeuwLILLZWfYn90R3CP5HJxcFA06aoiB5F4Iwbrb4USlOfDKZLUGqBpO17K8Ec7kPFER2meNtnYPbb2OULUHrlg0GY6JvNCPbZ99uRLAy3DNVcGZx7spFL5IGB6aOGi/hZb6WL5zY6a5S3KBpH79imMGuj7f/mgPmF7bZ1tjdl17DcQ12+qbqjhs0FmMH4E59SuDP/tISWWqkN3ayheqngxfpyxrcNDrn00GAE8GSjNC69jW7MPOAP4K5oATdpl9Tl1qkCb0h8YN2qMAyWck9e12GAvQJZuOhvUe7oAz6h6QFK1mPlFA8nB4tvoqyflw1usShWSesqSgUYPkrwN4SekHkzBiNJE9Mgo0USNhHiwS9ZxcVf0gNNRHWJNlcTmATbSM50IA/42WtglgvZmRguShJO8leQPJd5N8DFawe4HkB0bdvyaC5DtJfpnknSRXZNuo+7U1opGDwAjQxNnTa3JF7s10ZfHn0dxEhcthmmA2EGciU0dEbLsG99SMDLrLYHrkLnDlpGMkfSe4q5Yj6OEktOE6AFcA+CrahaMShoxtZtBmDz2Rce5OFTxKi/VcCYsybUArgNQ01GFZbKSryM8HMCckEg1DCGyY2EEtzZtzFXRZZJW70fasudgs6fJRd2JbwDYzaKt+AdaRQlJG+VtK8g6Yo93UQbvOQDwPDu6dKun54Ea5aJz6WRX5zM5iKbAmrsqagJtJfhzW4slnujZh5bRVIQUiGwySJ8EKf+eTfDtc7HcoJdeGiX5ZFk0N7tEFlF9FaxWWlW0jXJi3aSuDkYPkU5G3JampLr0JizRoNxQkL4Nnq3Mk7Uerqd0h6ZARd60rygZikocC+BsAP4e1R74OV47fDs4WTX7ihIQKSOyR5uKw4CL5JbBlmTmoEP9QUZNlcRksT7scDu6dJmk6nLRywbh2PGFoCMJe2f4Jhc8+P/492vqRBu3m4k26wowAgK5KP4xya8NEnYF4B0l3yiXRns8H98azwwlDx0m5/bMLnyV65BggDdrNxVJYlnQayc/CBXm/MNoudaDOQJyCe1snWLIfe50wBGwz7JGJApK3Avi4pGtIrkIrLfiEYeuwDAF1BuLKBRsSJhS6FSFOD+MxQApENgwkT4Srsy+DazdWqr04CiSWRUK6B8YfadBuIEJK+F/DPsGvIzejHWdp0oSEhIYhuUeaiTfh2ctkuKpL0wKQCQkJI0IatBuGQJX7IlzAd5akTT0OSUhI2IaQ3CMNA8mVcD3Ex0fdl4SEhOYhDdoJCQkJEwiJp52QkJAwgZAG7YSEhIQJhDRoJyQkJEwgpEE7ISEhYQIhDdoJCQkJEwj/D95nrEYHbkxNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df_test.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFinType2    0\n",
       "BsmtExposure    0\n",
       "Foundation      0\n",
       "TotalBsmtSF     0\n",
       "HalfBath        0\n",
       "BsmtFullBath    0\n",
       "GarageCars      0\n",
       "GarageArea      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['BsmtFinType2','BsmtExposure','Foundation','TotalBsmtSF','HalfBath',\n",
    "         'BsmtFullBath','GarageCars','GarageArea']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFinType2    0\n",
       "BsmtExposure    0\n",
       "Foundation      0\n",
       "TotalBsmtSF     0\n",
       "HalfBath        0\n",
       "BsmtFullBath    0\n",
       "GarageCars      1\n",
       "GarageArea      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['BsmtFinType2','BsmtExposure','Foundation','TotalBsmtSF','HalfBath',\n",
    "         'BsmtFullBath','GarageCars','GarageArea']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>882.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>763.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1168.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>789.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1300.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>882.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1405.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>483.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>525.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>855.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>836.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1590.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1544.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1698.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1822.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2846.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1671.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1370.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1324.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1145.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>847.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1629.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1595.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1468.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>641.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>967.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>660.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1573.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1594.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1625.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1664.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1491.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>1128.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1632.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1381.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1728.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1838.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1288.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>864.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>1652.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>630.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1104.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1224.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>912.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>996.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TotalBsmtSF  BsmtFullBath\n",
       "0           882.0           0.0\n",
       "1          1329.0           0.0\n",
       "2           928.0           0.0\n",
       "3           926.0           0.0\n",
       "4          1280.0           0.0\n",
       "5           763.0           0.0\n",
       "6          1168.0           1.0\n",
       "7           789.0           0.0\n",
       "8          1300.0           1.0\n",
       "9           882.0           1.0\n",
       "10         1405.0           1.0\n",
       "11          483.0           0.0\n",
       "12          525.0           0.0\n",
       "13          855.0           0.0\n",
       "14          836.0           0.0\n",
       "15         1590.0           0.0\n",
       "16         1544.0           0.0\n",
       "17         1698.0           0.0\n",
       "18         1822.0           0.0\n",
       "19         2846.0           1.0\n",
       "20         1671.0           1.0\n",
       "21         1370.0           0.0\n",
       "22         1324.0           0.0\n",
       "23         1145.0           0.0\n",
       "24          384.0           1.0\n",
       "25          847.0           0.0\n",
       "26         1629.0           0.0\n",
       "27         1595.0           0.0\n",
       "28         1218.0           0.0\n",
       "29         1468.0           1.0\n",
       "...           ...           ...\n",
       "1429        641.0           0.0\n",
       "1430        967.0           0.0\n",
       "1431          0.0           0.0\n",
       "1432        660.0           0.0\n",
       "1433        216.0           0.0\n",
       "1434       1573.0           2.0\n",
       "1435       1594.0           1.0\n",
       "1436       1625.0           0.0\n",
       "1437       1664.0           0.0\n",
       "1438       1491.0           0.0\n",
       "1439       1128.0           1.0\n",
       "1440       1632.0           1.0\n",
       "1441       1381.0           1.0\n",
       "1442       1728.0           1.0\n",
       "1443       1838.0           1.0\n",
       "1444          0.0           0.0\n",
       "1445       1288.0           2.0\n",
       "1446        264.0           0.0\n",
       "1447        864.0           1.0\n",
       "1448       1652.0           0.0\n",
       "1449        630.0           1.0\n",
       "1450        546.0           0.0\n",
       "1451       1104.0           1.0\n",
       "1452        546.0           0.0\n",
       "1453        546.0           0.0\n",
       "1454        546.0           0.0\n",
       "1455        546.0           0.0\n",
       "1456       1224.0           1.0\n",
       "1457        912.0           0.0\n",
       "1458        996.0           0.0\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['TotalBsmtSF','BsmtFullBath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['TotalBsmtSF']=df_test['TotalBsmtSF'].fillna(df_test['TotalBsmtSF'].mean())\n",
    "df_test['BsmtFullBath']=df_test['BsmtFullBath'].fillna(df_test['BsmtFullBath'].mode()[0])\n",
    "df_test['GarageCars']=df_test['GarageCars'].fillna(df_test['GarageCars'].mean())\n",
    "df_test['GarageArea']=df_test['GarageArea'].fillna(df_test['GarageArea'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFinType2    0\n",
       "BsmtExposure    0\n",
       "Foundation      0\n",
       "TotalBsmtSF     0\n",
       "HalfBath        0\n",
       "BsmtFullBath    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['BsmtFinType2','BsmtExposure','Foundation','TotalBsmtSF','HalfBath',\n",
    "         'BsmtFullBath']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "LotShape         0\n",
       "LandContour      0\n",
       "Utilities        0\n",
       "LotConfig        0\n",
       "LandSlope        0\n",
       "Neighborhood     0\n",
       "Condition1       0\n",
       "Condition2       0\n",
       "BldgType         0\n",
       "HouseStyle       0\n",
       "OverallQual      0\n",
       "OverallCond      0\n",
       "YearBuilt        0\n",
       "YearRemodAdd     0\n",
       "RoofStyle        0\n",
       "RoofMatl         0\n",
       "Exterior1st      0\n",
       "Exterior2nd      0\n",
       "MasVnrType       0\n",
       "MasVnrArea       0\n",
       "ExterQual        0\n",
       "ExterCond        0\n",
       "Foundation       0\n",
       "BsmtQual         0\n",
       "BsmtCond         0\n",
       "                ..\n",
       "BsmtHalfBath     0\n",
       "FullBath         0\n",
       "HalfBath         0\n",
       "BedroomAbvGr     0\n",
       "KitchenAbvGr     0\n",
       "KitchenQual      0\n",
       "TotRmsAbvGrd     0\n",
       "Functional       0\n",
       "Fireplaces       0\n",
       "FireplaceQu      0\n",
       "GarageType       0\n",
       "GarageYrBlt      0\n",
       "GarageFinish     0\n",
       "GarageCars       0\n",
       "GarageArea       0\n",
       "GarageQual       0\n",
       "GarageCond       0\n",
       "PavedDrive       0\n",
       "WoodDeckSF       0\n",
       "OpenPorchSF      0\n",
       "EnclosedPorch    0\n",
       "3SsnPorch        0\n",
       "ScreenPorch      0\n",
       "PoolArea         0\n",
       "MiscVal          0\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 76, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'MSZoning' has 5 categories\n",
      "Feature 'Street' has 2 categories\n",
      "Feature 'LotShape' has 4 categories\n",
      "Feature 'LandContour' has 4 categories\n",
      "Feature 'Utilities' has 1 categories\n",
      "Feature 'LotConfig' has 5 categories\n",
      "Feature 'LandSlope' has 3 categories\n",
      "Feature 'Neighborhood' has 25 categories\n",
      "Feature 'Condition1' has 9 categories\n",
      "Feature 'Condition2' has 5 categories\n",
      "Feature 'BldgType' has 5 categories\n",
      "Feature 'HouseStyle' has 7 categories\n",
      "Feature 'RoofStyle' has 6 categories\n",
      "Feature 'RoofMatl' has 4 categories\n",
      "Feature 'Exterior1st' has 13 categories\n",
      "Feature 'Exterior2nd' has 15 categories\n",
      "Feature 'MasVnrType' has 4 categories\n",
      "Feature 'ExterQual' has 4 categories\n",
      "Feature 'ExterCond' has 5 categories\n",
      "Feature 'Foundation' has 6 categories\n",
      "Feature 'BsmtQual' has 4 categories\n",
      "Feature 'BsmtCond' has 4 categories\n",
      "Feature 'BsmtExposure' has 4 categories\n",
      "Feature 'BsmtFinType1' has 6 categories\n",
      "Feature 'BsmtFinType2' has 6 categories\n",
      "Feature 'Heating' has 4 categories\n",
      "Feature 'HeatingQC' has 5 categories\n",
      "Feature 'CentralAir' has 2 categories\n",
      "Feature 'Electrical' has 4 categories\n",
      "Feature 'KitchenQual' has 4 categories\n",
      "Feature 'Functional' has 7 categories\n",
      "Feature 'FireplaceQu' has 5 categories\n",
      "Feature 'GarageType' has 6 categories\n",
      "Feature 'GarageFinish' has 3 categories\n",
      "Feature 'GarageQual' has 4 categories\n",
      "Feature 'GarageCond' has 5 categories\n",
      "Feature 'PavedDrive' has 3 categories\n",
      "Feature 'SaleType' has 9 categories\n",
      "Feature 'SaleCondition' has 6 categories\n",
      "\n",
      "Distribution of categories in service:\n",
      "RL         1118\n",
      "RM          242\n",
      "FV           74\n",
      "C (all)      15\n",
      "RH           10\n",
      "Name: MSZoning, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col_name in df_test.columns:\n",
    "    if df_test[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df_test[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "#see how distributed the feature service is, it is evenly distributed and therefore we need to make dummies for all.\n",
    "print()\n",
    "print('Distribution of categories in service:')\n",
    "print(df_test['MSZoning'].value_counts().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'MSZoning' has 5 categories\n",
      "Feature 'Street' has 2 categories\n",
      "Feature 'LotShape' has 4 categories\n",
      "Feature 'LandContour' has 4 categories\n",
      "Feature 'Utilities' has 2 categories\n",
      "Feature 'LotConfig' has 5 categories\n",
      "Feature 'LandSlope' has 3 categories\n",
      "Feature 'Neighborhood' has 25 categories\n",
      "Feature 'Condition1' has 9 categories\n",
      "Feature 'Condition2' has 8 categories\n",
      "Feature 'BldgType' has 5 categories\n",
      "Feature 'HouseStyle' has 8 categories\n",
      "Feature 'RoofStyle' has 6 categories\n",
      "Feature 'RoofMatl' has 8 categories\n",
      "Feature 'Exterior1st' has 15 categories\n",
      "Feature 'Exterior2nd' has 16 categories\n",
      "Feature 'MasVnrType' has 4 categories\n",
      "Feature 'ExterQual' has 4 categories\n",
      "Feature 'ExterCond' has 5 categories\n",
      "Feature 'Foundation' has 6 categories\n",
      "Feature 'BsmtQual' has 4 categories\n",
      "Feature 'BsmtCond' has 4 categories\n",
      "Feature 'BsmtExposure' has 4 categories\n",
      "Feature 'BsmtFinType1' has 6 categories\n",
      "Feature 'BsmtFinType2' has 6 categories\n",
      "Feature 'Heating' has 6 categories\n",
      "Feature 'HeatingQC' has 5 categories\n",
      "Feature 'CentralAir' has 2 categories\n",
      "Feature 'Electrical' has 5 categories\n",
      "Feature 'KitchenQual' has 4 categories\n",
      "Feature 'Functional' has 7 categories\n",
      "Feature 'FireplaceQu' has 5 categories\n",
      "Feature 'GarageType' has 6 categories\n",
      "Feature 'GarageFinish' has 3 categories\n",
      "Feature 'GarageQual' has 5 categories\n",
      "Feature 'GarageCond' has 5 categories\n",
      "Feature 'PavedDrive' has 3 categories\n",
      "Feature 'SaleType' has 9 categories\n",
      "Feature 'SaleCondition' has 6 categories\n",
      "\n",
      "Distribution of categories in service:\n",
      "RL         1150\n",
      "RM          218\n",
      "FV           65\n",
      "RH           16\n",
      "C (all)      10\n",
      "Name: MSZoning, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col_name in df.columns:\n",
    "    if df[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "#see how distributed the feature service is, it is evenly distributed and therefore we need to make dummies for all.\n",
    "print()\n",
    "print('Distribution of categories in service:')\n",
    "print(df['MSZoning'].value_counts().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MSZoning Street LotShape LandContour Utilities LotConfig LandSlope  \\\n",
       "0       RL   Pave      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "1       RL   Pave      Reg         Lvl    AllPub       FR2       Gtl   \n",
       "2       RL   Pave      IR1         Lvl    AllPub    Inside       Gtl   \n",
       "3       RL   Pave      IR1         Lvl    AllPub    Corner       Gtl   \n",
       "4       RL   Pave      IR1         Lvl    AllPub       FR2       Gtl   \n",
       "\n",
       "  Neighborhood Condition1 Condition2      ...      KitchenQual Functional  \\\n",
       "0      CollgCr       Norm       Norm      ...               Gd        Typ   \n",
       "1      Veenker      Feedr       Norm      ...               TA        Typ   \n",
       "2      CollgCr       Norm       Norm      ...               Gd        Typ   \n",
       "3      Crawfor       Norm       Norm      ...               Gd        Typ   \n",
       "4      NoRidge       Norm       Norm      ...               Gd        Typ   \n",
       "\n",
       "  FireplaceQu GarageType GarageFinish GarageQual GarageCond PavedDrive  \\\n",
       "0          Gd     Attchd          RFn         TA         TA          Y   \n",
       "1          TA     Attchd          RFn         TA         TA          Y   \n",
       "2          TA     Attchd          RFn         TA         TA          Y   \n",
       "3          Gd     Detchd          Unf         TA         TA          Y   \n",
       "4          TA     Attchd          RFn         TA         TA          Y   \n",
       "\n",
       "  SaleType SaleCondition  \n",
       "0       WD        Normal  \n",
       "1       WD        Normal  \n",
       "2       WD        Normal  \n",
       "3       WD       Abnorml  \n",
       "4       WD        Normal  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "# insert code to get a list of categorical columns into a variable, categorical_columns\n",
    "catg_columns=[ 'MSZoning',    'Street'  , 'LotShape',    'LandContour',    'Utilities'  ,  'LotConfig'  ,  'LandSlope' ,  \n",
    " 'Neighborhood',    'Condition1',    'Condition2'  ,  'BldgType' ,  'HouseStyle'   , 'RoofStyle'  ,  'RoofMatl'    ,'Exterior1st'  , \n",
    " 'Exterior2nd'   , 'MasVnrType'  ,  'ExterQual'  ,  'ExterCond'  ,  'Foundation'   , 'BsmtQual'    ,'BsmtCond'   , 'BsmtExposure' ,  \n",
    " 'BsmtFinType1'   ,'BsmtFinType2'  ,  'Heating'  ,  'HeatingQC'    ,'CentralAir'   , 'Electrical'  ,  'KitchenQual',   'Functional' ,  \n",
    " 'FireplaceQu'    ,'GarageType' , 'GarageFinish',  'GarageQual' , 'GarageCond'  ,  'PavedDrive'   , 'SaleType'  ,  'SaleCondition'   ] \n",
    " # Get the categorical values into a 2D numpy array\n",
    "df_catg_values = df[catg_columns]\n",
    "df_catg_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RH</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>StoneBr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MSZoning Street LotShape LandContour Utilities LotConfig LandSlope  \\\n",
       "0       RH   Pave      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "1       RL   Pave      IR1         Lvl    AllPub    Corner       Gtl   \n",
       "2       RL   Pave      IR1         Lvl    AllPub    Inside       Gtl   \n",
       "3       RL   Pave      IR1         Lvl    AllPub    Inside       Gtl   \n",
       "4       RL   Pave      IR1         HLS    AllPub    Inside       Gtl   \n",
       "\n",
       "  Neighborhood Condition1 Condition2      ...      KitchenQual Functional  \\\n",
       "0        NAmes      Feedr       Norm      ...               TA        Typ   \n",
       "1        NAmes       Norm       Norm      ...               Gd        Typ   \n",
       "2      Gilbert       Norm       Norm      ...               TA        Typ   \n",
       "3      Gilbert       Norm       Norm      ...               Gd        Typ   \n",
       "4      StoneBr       Norm       Norm      ...               Gd        Typ   \n",
       "\n",
       "  FireplaceQu GarageType GarageFinish GarageQual GarageCond PavedDrive  \\\n",
       "0          Gd     Attchd          Unf         TA         TA          Y   \n",
       "1          Gd     Attchd          Unf         TA         TA          Y   \n",
       "2          TA     Attchd          Fin         TA         TA          Y   \n",
       "3          Gd     Attchd          Fin         TA         TA          Y   \n",
       "4          Gd     Attchd          RFn         TA         TA          Y   \n",
       "\n",
       "  SaleType SaleCondition  \n",
       "0       WD        Normal  \n",
       "1       WD        Normal  \n",
       "2       WD        Normal  \n",
       "3       WD        Normal  \n",
       "4       WD        Normal  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_catg_values = df_test[catg_columns]\n",
    "df_test_catg_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1459 entries, 0 to 1459\n",
      "Data columns (total 39 columns):\n",
      "MSZoning         1459 non-null object\n",
      "Street           1459 non-null object\n",
      "LotShape         1459 non-null object\n",
      "LandContour      1459 non-null object\n",
      "Utilities        1459 non-null object\n",
      "LotConfig        1459 non-null object\n",
      "LandSlope        1459 non-null object\n",
      "Neighborhood     1459 non-null object\n",
      "Condition1       1459 non-null object\n",
      "Condition2       1459 non-null object\n",
      "BldgType         1459 non-null object\n",
      "HouseStyle       1459 non-null object\n",
      "RoofStyle        1459 non-null object\n",
      "RoofMatl         1459 non-null object\n",
      "Exterior1st      1459 non-null object\n",
      "Exterior2nd      1459 non-null object\n",
      "MasVnrType       1459 non-null object\n",
      "ExterQual        1459 non-null object\n",
      "ExterCond        1459 non-null object\n",
      "Foundation       1459 non-null object\n",
      "BsmtQual         1459 non-null object\n",
      "BsmtCond         1459 non-null object\n",
      "BsmtExposure     1459 non-null object\n",
      "BsmtFinType1     1459 non-null object\n",
      "BsmtFinType2     1459 non-null object\n",
      "Heating          1459 non-null object\n",
      "HeatingQC        1459 non-null object\n",
      "CentralAir       1459 non-null object\n",
      "Electrical       1459 non-null object\n",
      "KitchenQual      1459 non-null object\n",
      "Functional       1459 non-null object\n",
      "FireplaceQu      1459 non-null object\n",
      "GarageType       1459 non-null object\n",
      "GarageFinish     1459 non-null object\n",
      "GarageQual       1459 non-null object\n",
      "GarageCond       1459 non-null object\n",
      "PavedDrive       1459 non-null object\n",
      "SaleType         1459 non-null object\n",
      "SaleCondition    1459 non-null object\n",
      "dtypes: object(39)\n",
      "memory usage: 455.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_catg_values.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSZoning  Street  LotShape  LandContour  Utilities  LotConfig  LandSlope  \\\n",
       "0         3       1         3            3          0          4          0   \n",
       "1         3       1         3            3          0          2          0   \n",
       "2         3       1         0            3          0          4          0   \n",
       "3         3       1         0            3          0          0          0   \n",
       "4         3       1         0            3          0          2          0   \n",
       "\n",
       "   Neighborhood  Condition1  Condition2      ...        KitchenQual  \\\n",
       "0             5           2           2      ...                  2   \n",
       "1            24           1           2      ...                  3   \n",
       "2             5           2           2      ...                  2   \n",
       "3             6           2           2      ...                  2   \n",
       "4            15           2           2      ...                  2   \n",
       "\n",
       "   Functional  FireplaceQu  GarageType  GarageFinish  GarageQual  GarageCond  \\\n",
       "0           6            2           1             1           4           4   \n",
       "1           6            4           1             1           4           4   \n",
       "2           6            4           1             1           4           4   \n",
       "3           6            2           5             2           4           4   \n",
       "4           6            4           1             1           4           4   \n",
       "\n",
       "   PavedDrive  SaleType  SaleCondition  \n",
       "0           2         8              4  \n",
       "1           2         8              4  \n",
       "2           2         8              4  \n",
       "3           2         8              0  \n",
       "4           2         8              4  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_catg_val_enc=df_catg_values.apply(LabelEncoder().fit_transform)\n",
    "df_catg_val_enc.head()\n",
    "#df=pd.get_dummies(df_catg_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSZoning  Street  LotShape  LandContour  Utilities  LotConfig  LandSlope  \\\n",
       "0         2       1         3            3          0          4          0   \n",
       "1         3       1         0            3          0          0          0   \n",
       "2         3       1         0            3          0          4          0   \n",
       "3         3       1         0            3          0          4          0   \n",
       "4         3       1         0            1          0          4          0   \n",
       "\n",
       "   Neighborhood  Condition1  Condition2      ...        KitchenQual  \\\n",
       "0            12           1           2      ...                  3   \n",
       "1            12           2           2      ...                  2   \n",
       "2             8           2           2      ...                  3   \n",
       "3             8           2           2      ...                  2   \n",
       "4            22           2           2      ...                  2   \n",
       "\n",
       "   Functional  FireplaceQu  GarageType  GarageFinish  GarageQual  GarageCond  \\\n",
       "0           6            2           1             2           3           4   \n",
       "1           6            2           1             2           3           4   \n",
       "2           6            4           1             0           3           4   \n",
       "3           6            2           1             0           3           4   \n",
       "4           6            2           1             1           3           4   \n",
       "\n",
       "   PavedDrive  SaleType  SaleCondition  \n",
       "0           2         8              4  \n",
       "1           2         8              4  \n",
       "2           2         8              4  \n",
       "3           2         8              4  \n",
       "4           2         8              4  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_catg_val_enc=df_test_catg_values.apply(LabelEncoder().fit_transform)\n",
    "df_test_catg_val_enc.head()\n",
    "#df=pd.get_dummies(df_catg_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['MSZoning',    'Street'  , 'LotShape',    'LandContour',    'Utilities'  ,  'LotConfig'  ,  'LandSlope' ,  \n",
    " 'Neighborhood',    'Condition1',    'Condition2'  ,  'BldgType' ,  'HouseStyle'   , 'RoofStyle'  ,  'RoofMatl'    ,'Exterior1st'  , \n",
    " 'Exterior2nd'   , 'MasVnrType'  ,  'ExterQual'  ,  'ExterCond'  ,  'Foundation'   , 'BsmtQual'    ,'BsmtCond'   , 'BsmtExposure' ,  \n",
    " 'BsmtFinType1'   ,'BsmtFinType2'  ,  'Heating'  ,  'HeatingQC'    ,'CentralAir'   , 'Electrical'  ,  'KitchenQual',   'Functional' ,  \n",
    " 'FireplaceQu'    ,'GarageType' , 'GarageFinish',  'GarageQual' , 'GarageCond'  ,  'PavedDrive'   , 'SaleType'  ,  'SaleCondition'  ],axis=1,inplace=True)\n",
    "\n",
    "df_test.drop(['MSZoning',    'Street'  , 'LotShape',    'LandContour',    'Utilities'  ,  'LotConfig'  ,  'LandSlope' ,  \n",
    " 'Neighborhood',    'Condition1',    'Condition2'  ,  'BldgType' ,  'HouseStyle'   , 'RoofStyle'  ,  'RoofMatl'    ,'Exterior1st'  , \n",
    " 'Exterior2nd'   , 'MasVnrType'  ,  'ExterQual'  ,  'ExterCond'  ,  'Foundation'   , 'BsmtQual'    ,'BsmtCond'   , 'BsmtExposure' ,  \n",
    " 'BsmtFinType1'   ,'BsmtFinType2'  ,  'Heating'  ,  'HeatingQC'    ,'CentralAir'   , 'Electrical'  ,  'KitchenQual',   'Functional' ,  \n",
    " 'FireplaceQu'    ,'GarageType' , 'GarageFinish',  'GarageQual' , 'GarageCond'  ,  'PavedDrive'   , 'SaleType'  ,  'SaleCondition'  ],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2    ...      WoodDeckSF  \\\n",
       "0          2003       196.0         706           0    ...               0   \n",
       "1          1976         0.0         978           0    ...             298   \n",
       "2          2002       162.0         486           0    ...               0   \n",
       "3          1970         0.0         216           0    ...               0   \n",
       "4          2000       350.0         655           0    ...             192   \n",
       "\n",
       "   OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "0           61              0          0            0         0        0   \n",
       "1            0              0          0            0         0        0   \n",
       "2           42              0          0            0         0        0   \n",
       "3           35            272          0            0         0        0   \n",
       "4           84              0          0            0         0        0   \n",
       "\n",
       "   MoSold  YrSold  SalePrice  \n",
       "0       2    2008     208500  \n",
       "1       5    2007     181500  \n",
       "2       9    2008     223500  \n",
       "3       2    2006     140000  \n",
       "4      12    2008     250000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 37)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.concat([df,df_catg_val_enc], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 76)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.concat([df_test,df_test_catg_val_enc], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 75)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2      ...        \\\n",
       "0          2003       196.0         706           0      ...         \n",
       "1          1976         0.0         978           0      ...         \n",
       "2          2002       162.0         486           0      ...         \n",
       "3          1970         0.0         216           0      ...         \n",
       "4          2000       350.0         655           0      ...         \n",
       "\n",
       "   KitchenQual  Functional  FireplaceQu  GarageType  GarageFinish  GarageQual  \\\n",
       "0            2           6            2           1             1           4   \n",
       "1            3           6            4           1             1           4   \n",
       "2            2           6            4           1             1           4   \n",
       "3            2           6            2           5             2           4   \n",
       "4            2           6            4           1             1           4   \n",
       "\n",
       "   GarageCond  PavedDrive  SaleType  SaleCondition  \n",
       "0           4           2         8              4  \n",
       "1           4           2         8              4  \n",
       "2           4           2         8              4  \n",
       "3           4           2         8              0  \n",
       "4           4           2         8              4  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          20         80.0    11622            5            6       1961   \n",
       "1          20         81.0    14267            6            6       1958   \n",
       "2          60         74.0    13830            5            5       1997   \n",
       "3          60         78.0     9978            6            6       1998   \n",
       "4         120         43.0     5005            8            5       1992   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2      ...        \\\n",
       "0          1961         0.0       468.0       144.0      ...         \n",
       "1          1958       108.0       923.0         0.0      ...         \n",
       "2          1998         0.0       791.0         0.0      ...         \n",
       "3          1998        20.0       602.0         0.0      ...         \n",
       "4          1992         0.0       263.0         0.0      ...         \n",
       "\n",
       "   KitchenQual  Functional  FireplaceQu  GarageType  GarageFinish  GarageQual  \\\n",
       "0            3           6            2           1             2           3   \n",
       "1            2           6            2           1             2           3   \n",
       "2            3           6            4           1             0           3   \n",
       "3            2           6            2           1             0           3   \n",
       "4            2           6            2           1             1           3   \n",
       "\n",
       "   GarageCond  PavedDrive  SaleType  SaleCondition  \n",
       "0           4           2         8              4  \n",
       "1           4           2         8              4  \n",
       "2           4           2         8              4  \n",
       "3           4           2         8              4  \n",
       "4           4           2         8              4  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "OverallQual      0\n",
       "OverallCond      0\n",
       "YearBuilt        0\n",
       "YearRemodAdd     0\n",
       "MasVnrArea       0\n",
       "BsmtFinSF1       0\n",
       "BsmtFinSF2       0\n",
       "BsmtUnfSF        0\n",
       "TotalBsmtSF      0\n",
       "1stFlrSF         0\n",
       "2ndFlrSF         0\n",
       "LowQualFinSF     0\n",
       "GrLivArea        0\n",
       "BsmtFullBath     0\n",
       "BsmtHalfBath     0\n",
       "FullBath         0\n",
       "HalfBath         0\n",
       "BedroomAbvGr     0\n",
       "KitchenAbvGr     0\n",
       "TotRmsAbvGrd     0\n",
       "Fireplaces       0\n",
       "GarageYrBlt      0\n",
       "GarageCars       0\n",
       "GarageArea       0\n",
       "WoodDeckSF       0\n",
       "OpenPorchSF      0\n",
       "EnclosedPorch    0\n",
       "                ..\n",
       "Condition2       0\n",
       "BldgType         0\n",
       "HouseStyle       0\n",
       "RoofStyle        0\n",
       "RoofMatl         0\n",
       "Exterior1st      0\n",
       "Exterior2nd      0\n",
       "MasVnrType       0\n",
       "ExterQual        0\n",
       "ExterCond        0\n",
       "Foundation       0\n",
       "BsmtQual         0\n",
       "BsmtCond         0\n",
       "BsmtExposure     0\n",
       "BsmtFinType1     0\n",
       "BsmtFinType2     0\n",
       "Heating          0\n",
       "HeatingQC        0\n",
       "CentralAir       0\n",
       "Electrical       0\n",
       "KitchenQual      0\n",
       "Functional       0\n",
       "FireplaceQu      0\n",
       "GarageType       0\n",
       "GarageFinish     0\n",
       "GarageQual       0\n",
       "GarageCond       0\n",
       "PavedDrive       0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "Length: 76, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train_data\n",
    "test=test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.drop(['SalePrice'],axis=1)\n",
    "y_train=train['SalePrice']\n",
    "#X_test\n",
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_classifier = LogisticRegression(penalty = 'l1', random_state = 0)\n",
    "clf = lr_classifier.fit(X_train, y_train)\n",
    "y_test_predicted = clf.predict(test)\n",
    "#y_pred=regressor.predict(df_Test.drop(['SalePrice'],axis=1))\n",
    "#_accuracy_ = accuracy_score(y_test, y_test_predicted, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciton and selecting the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 568, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 605, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 635, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 98, in __call__\n    **self._kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\", line 170, in mean_absolute_error\n    y_true, y_pred, multioutput)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\", line 77, in _check_reg_targets\n    y_pred = check_array(y_pred, ensure_2d=False)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 573, in check_array\n    allow_nan=force_all_finite == 'allow-nan')\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 56, in _assert_all_finite\n    raise ValueError(msg_err.format(type_err, X.dtype))\nValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-372-243a35751c12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrandom_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1515\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 174)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121033.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155717.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185616.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189161.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175323.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
       "0           0.0           0.0      270.0              0      ...           0   \n",
       "1           0.0           0.0      406.0              0      ...           0   \n",
       "2           0.0           0.0      137.0              0      ...           0   \n",
       "3           0.0           0.0      324.0              0      ...           0   \n",
       "4           0.0           0.0     1017.0              0      ...           0   \n",
       "\n",
       "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
       "0    1       1        0        0        0       0    0  0  121033.398438  \n",
       "1    1       1        0        0        0       0    0  0  155717.390625  \n",
       "2    1       1        0        0        0       0    0  0  185616.859375  \n",
       "3    1       1        0        0        0       0    0  0  189161.546875  \n",
       "4    1       1        0        0        0       0    1  0  175323.750000  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0 ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0 ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0 ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0 ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(df_Test.drop(['SalePrice'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119179.125, 158328.88 , 183704.81 , ..., 165757.22 , 118693.11 ,\n",
       "       230294.19 ], dtype=float32)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.columns=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=df_Train['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.column=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,temp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121033.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155717.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185616.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189161.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175323.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
       "0           0.0           0.0      270.0              0      ...           0   \n",
       "1           0.0           0.0      406.0              0      ...           0   \n",
       "2           0.0           0.0      137.0              0      ...           0   \n",
       "3           0.0           0.0      324.0              0      ...           0   \n",
       "4           0.0           0.0     1017.0              0      ...           0   \n",
       "\n",
       "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
       "0    1       1        0        0        0       0    0  0  121033.398438  \n",
       "1    1       1        0        0        0       0    0  0  155717.390625  \n",
       "2    1       1        0        0        0       0    0  0  185616.859375  \n",
       "3    1       1        0        0        0       0    0  0  189161.546875  \n",
       "4    1       1        0        0        0       0    1  0  175323.750000  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test=pd.concat([df_Test,pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 175)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,df_Test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2304 samples, validate on 577 samples\n",
      "Epoch 1/1000\n",
      "2304/2304 [==============================] - 2s 1ms/step - loss: 113530.5093 - val_loss: 56624.8765\n",
      "Epoch 2/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 62615.1298 - val_loss: 50444.1900\n",
      "Epoch 3/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 56279.5739 - val_loss: 44504.8296\n",
      "Epoch 4/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 50261.0310 - val_loss: 39335.5723\n",
      "Epoch 5/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 44449.5163 - val_loss: 35396.5539\n",
      "Epoch 6/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 40090.4315 - val_loss: 35178.2237\n",
      "Epoch 7/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 37493.4126 - val_loss: 31983.3301\n",
      "Epoch 8/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 36462.1401 - val_loss: 34241.1639\n",
      "Epoch 9/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 35635.4539 - val_loss: 32087.6040\n",
      "Epoch 10/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 35851.5885 - val_loss: 32125.1113\n",
      "Epoch 11/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 35622.6530 - val_loss: 31914.6602\n",
      "Epoch 12/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 35187.7144 - val_loss: 31882.3983\n",
      "Epoch 13/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 35196.1213 - val_loss: 32342.4395\n",
      "Epoch 14/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 34929.6660 - val_loss: 31565.0875\n",
      "Epoch 15/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 34672.9052 - val_loss: 32177.3833\n",
      "Epoch 16/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 34501.2563 - val_loss: 31293.5959\n",
      "Epoch 17/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 34804.2316 - val_loss: 31182.3204\n",
      "Epoch 18/1000\n",
      "2304/2304 [==============================] - 2s 778us/step - loss: 34455.4584 - val_loss: 31376.9020\n",
      "Epoch 19/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 34377.8071 - val_loss: 31301.4047\n",
      "Epoch 20/1000\n",
      "2304/2304 [==============================] - 1s 477us/step - loss: 34164.2543 - val_loss: 31142.9020\n",
      "Epoch 21/1000\n",
      "2304/2304 [==============================] - 1s 469us/step - loss: 34009.0316 - val_loss: 31243.3016\n",
      "Epoch 22/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 33660.4401 - val_loss: 31494.8445\n",
      "Epoch 23/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 33812.4372 - val_loss: 31299.1932\n",
      "Epoch 24/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 33589.9288 - val_loss: 31848.2731\n",
      "Epoch 25/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 33607.1809 - val_loss: 30390.6748\n",
      "Epoch 26/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 33473.9579 - val_loss: 30910.1593\n",
      "Epoch 27/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 33236.2349 - val_loss: 30219.5441\n",
      "Epoch 28/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 33243.2710 - val_loss: 30179.0993\n",
      "Epoch 29/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 32929.2295 - val_loss: 30128.3545\n",
      "Epoch 30/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 32963.0511 - val_loss: 30510.0357\n",
      "Epoch 31/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 32787.1626 - val_loss: 29853.5188\n",
      "Epoch 32/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 32766.8486 - val_loss: 30704.6890\n",
      "Epoch 33/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 32790.5330 - val_loss: 30381.5674\n",
      "Epoch 34/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 32740.6885 - val_loss: 29614.6660\n",
      "Epoch 35/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 32658.3221 - val_loss: 30323.1913\n",
      "Epoch 36/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 32570.0888 - val_loss: 30407.4534\n",
      "Epoch 37/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 32189.7531 - val_loss: 30379.3509\n",
      "Epoch 38/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 32140.4911 - val_loss: 29347.5356\n",
      "Epoch 39/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 31913.3835 - val_loss: 29861.8741\n",
      "Epoch 40/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 32135.0634 - val_loss: 29108.2475\n",
      "Epoch 41/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 32026.9856 - val_loss: 29142.3169\n",
      "Epoch 42/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 31792.7488 - val_loss: 29323.2182\n",
      "Epoch 43/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 31622.7127 - val_loss: 29028.4757\n",
      "Epoch 44/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 31769.7568 - val_loss: 29493.1864\n",
      "Epoch 45/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 31732.7656 - val_loss: 29812.4935\n",
      "Epoch 46/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 31434.8387 - val_loss: 28903.6488\n",
      "Epoch 47/1000\n",
      "2304/2304 [==============================] - 1s 414us/step - loss: 31234.3539 - val_loss: 28895.0965\n",
      "Epoch 48/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 31151.4855 - val_loss: 28861.3638\n",
      "Epoch 49/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 31274.5573 - val_loss: 29427.3137\n",
      "Epoch 50/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 31510.8220 - val_loss: 28567.3384\n",
      "Epoch 51/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 31460.1977 - val_loss: 28814.4977\n",
      "Epoch 52/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 31085.8429 - val_loss: 28524.2395\n",
      "Epoch 53/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 30989.9977 - val_loss: 28568.5788\n",
      "Epoch 54/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 31092.4584 - val_loss: 28378.7455\n",
      "Epoch 55/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 30932.9268 - val_loss: 30094.5473\n",
      "Epoch 56/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 30684.4676 - val_loss: 28414.4087\n",
      "Epoch 57/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 30493.6564 - val_loss: 29508.0253\n",
      "Epoch 58/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 30652.6024 - val_loss: 28326.5143\n",
      "Epoch 59/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 30778.1669 - val_loss: 28056.4234\n",
      "Epoch 60/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 30424.7307 - val_loss: 28010.0378\n",
      "Epoch 61/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 30072.8579 - val_loss: 28027.6187\n",
      "Epoch 62/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 30334.3219 - val_loss: 28459.9857\n",
      "Epoch 63/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 30427.8750 - val_loss: 29863.5684\n",
      "Epoch 64/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 30285.2018 - val_loss: 28957.1549\n",
      "Epoch 65/1000\n",
      "2304/2304 [==============================] - 1s 417us/step - loss: 30310.4877 - val_loss: 28183.0357\n",
      "Epoch 66/1000\n",
      "2304/2304 [==============================] - 1s 405us/step - loss: 30276.2501 - val_loss: 27665.3018\n",
      "Epoch 67/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 29832.1718 - val_loss: 27712.5372\n",
      "Epoch 68/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 30272.4041 - val_loss: 27718.7824\n",
      "Epoch 69/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 30113.7119 - val_loss: 28000.3839\n",
      "Epoch 70/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 29942.6214 - val_loss: 27786.2428\n",
      "Epoch 71/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 29859.0674 - val_loss: 27215.5401\n",
      "Epoch 72/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 29209.5491 - val_loss: 27173.5760\n",
      "Epoch 73/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 29919.4843 - val_loss: 27220.3691\n",
      "Epoch 74/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 29509.6134 - val_loss: 27340.0882\n",
      "Epoch 75/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 29708.4845 - val_loss: 27312.6990\n",
      "Epoch 76/1000\n",
      "2304/2304 [==============================] - 1s 473us/step - loss: 29519.9725 - val_loss: 27508.6494\n",
      "Epoch 77/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 29357.4566 - val_loss: 26867.6287\n",
      "Epoch 78/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 29159.6736 - val_loss: 26893.8640\n",
      "Epoch 79/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 29366.9112 - val_loss: 26603.1912\n",
      "Epoch 80/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 29120.4931 - val_loss: 26661.9235\n",
      "Epoch 81/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 28946.7935 - val_loss: 27871.8099\n",
      "Epoch 82/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 29138.3855 - val_loss: 26531.3914\n",
      "Epoch 83/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 28846.1910 - val_loss: 28481.5947\n",
      "Epoch 84/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 29017.1691 - val_loss: 26508.0993\n",
      "Epoch 85/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 28775.6919 - val_loss: 26779.5843\n",
      "Epoch 86/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 29089.2547 - val_loss: 27172.3217\n",
      "Epoch 87/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 28686.1871 - val_loss: 26091.4350\n",
      "Epoch 88/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 28698.4660 - val_loss: 26102.4028\n",
      "Epoch 89/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 28699.3697 - val_loss: 26289.4353\n",
      "Epoch 90/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 28489.5871 - val_loss: 27897.5505\n",
      "Epoch 91/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 28665.1914 - val_loss: 25854.9589\n",
      "Epoch 92/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 28285.7090 - val_loss: 25977.9663\n",
      "Epoch 93/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 28285.7983 - val_loss: 25438.4628\n",
      "Epoch 94/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 28321.3720 - val_loss: 25585.6818\n",
      "Epoch 95/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 28190.3902 - val_loss: 25334.2817\n",
      "Epoch 96/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 28360.6425 - val_loss: 25095.3392\n",
      "Epoch 97/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 28196.4608 - val_loss: 24977.6499\n",
      "Epoch 98/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 28143.1103 - val_loss: 24957.5144\n",
      "Epoch 99/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 28541.725 - 1s 465us/step - loss: 28404.1788 - val_loss: 25377.6330\n",
      "Epoch 100/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 27923.1122 - val_loss: 25035.9833\n",
      "Epoch 101/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 28224.6294 - val_loss: 24864.9644\n",
      "Epoch 102/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 27838.1132 - val_loss: 26435.8536\n",
      "Epoch 103/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 27936.2079 - val_loss: 24885.9012\n",
      "Epoch 104/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 27583.212 - 1s 450us/step - loss: 27619.0787 - val_loss: 24613.4044\n",
      "Epoch 105/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 27628.1560 - val_loss: 24228.4823\n",
      "Epoch 106/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 27878.6943 - val_loss: 24845.3175\n",
      "Epoch 107/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 27493.7438 - val_loss: 24612.2324\n",
      "Epoch 108/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 27134.2120 - val_loss: 25914.3079\n",
      "Epoch 109/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 27448.0619 - val_loss: 23640.7174\n",
      "Epoch 110/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 27225.6602 - val_loss: 24300.4790\n",
      "Epoch 111/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 27457.5783 - val_loss: 23591.0836\n",
      "Epoch 112/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 27562.5854 - val_loss: 23601.4916\n",
      "Epoch 113/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 26970.8130 - val_loss: 23496.5879\n",
      "Epoch 114/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 27141.8372 - val_loss: 24716.6597\n",
      "Epoch 115/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 26687.5030 - val_loss: 25936.5065\n",
      "Epoch 116/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 26811.0217 - val_loss: 23067.7963\n",
      "Epoch 117/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 26862.9685 - val_loss: 23789.6916\n",
      "Epoch 118/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 26478.2679 - val_loss: 24595.6749\n",
      "Epoch 119/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 26766.5188 - val_loss: 23377.8840\n",
      "Epoch 120/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 26545.6570 - val_loss: 22453.2940\n",
      "Epoch 121/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 26442.3213 - val_loss: 22567.1628\n",
      "Epoch 122/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 26011.6722 - val_loss: 24087.4123\n",
      "Epoch 123/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 26506.6031 - val_loss: 22453.8540\n",
      "Epoch 124/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 26042.1024 - val_loss: 22348.5490\n",
      "Epoch 125/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 26685.7815 - val_loss: 21968.0753\n",
      "Epoch 126/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 25654.7254 - val_loss: 22398.2175\n",
      "Epoch 127/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 25909.7507 - val_loss: 21961.1548\n",
      "Epoch 128/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 25938.8809 - val_loss: 21437.6150\n",
      "Epoch 129/1000\n",
      "2304/2304 [==============================] - 1s 476us/step - loss: 25268.5747 - val_loss: 21907.7049\n",
      "Epoch 130/1000\n",
      "2304/2304 [==============================] - 1s 470us/step - loss: 25609.2470 - val_loss: 21246.5780\n",
      "Epoch 131/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 25023.4624 - val_loss: 24637.6923\n",
      "Epoch 132/1000\n",
      "2304/2304 [==============================] - 1s 520us/step - loss: 25366.8912 - val_loss: 21211.1705\n",
      "Epoch 133/1000\n",
      "2304/2304 [==============================] - 1s 479us/step - loss: 25424.9557 - val_loss: 21021.8191\n",
      "Epoch 134/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 25343.5929 - val_loss: 21586.6650\n",
      "Epoch 135/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 24995.2175 - val_loss: 21105.6569\n",
      "Epoch 136/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 24986.7363 - val_loss: 20605.5033\n",
      "Epoch 137/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 25225.4030 - val_loss: 20552.5941\n",
      "Epoch 138/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 25014.9195 - val_loss: 21813.1205\n",
      "Epoch 139/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 24983.0982 - val_loss: 20684.3204\n",
      "Epoch 140/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 24864.2334 - val_loss: 20245.8430\n",
      "Epoch 141/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 24915.6213 - val_loss: 19954.3808\n",
      "Epoch 142/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 24832.0423 - val_loss: 22799.6597\n",
      "Epoch 143/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 24758.2035 - val_loss: 20148.5544\n",
      "Epoch 144/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 24726.4656 - val_loss: 19816.7254\n",
      "Epoch 145/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 24342.4105 - val_loss: 21506.8392\n",
      "Epoch 146/1000\n",
      "2304/2304 [==============================] - 1s 494us/step - loss: 24704.4509 - val_loss: 19672.9874\n",
      "Epoch 147/1000\n",
      "2304/2304 [==============================] - 1s 483us/step - loss: 24873.8309 - val_loss: 19765.3019\n",
      "Epoch 148/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 24126.7666 - val_loss: 21504.0878\n",
      "Epoch 149/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 24424.1095 - val_loss: 21462.0763\n",
      "Epoch 150/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 24470.7238 - val_loss: 19617.8413\n",
      "Epoch 151/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 24235.2767 - val_loss: 20478.6877\n",
      "Epoch 152/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 23886.3026 - val_loss: 19679.8546\n",
      "Epoch 153/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 24203.4083 - val_loss: 19225.7126\n",
      "Epoch 154/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 24125.6937 - val_loss: 18712.8627\n",
      "Epoch 155/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 23699.3783 - val_loss: 19005.6716\n",
      "Epoch 156/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 23628.8058 - val_loss: 20574.2034\n",
      "Epoch 157/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 23527.5995 - val_loss: 20440.9397\n",
      "Epoch 158/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 23367.5987 - val_loss: 20027.8654\n",
      "Epoch 159/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 23393.3923 - val_loss: 18406.9154\n",
      "Epoch 160/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 23547.7516 - val_loss: 19510.1907\n",
      "Epoch 161/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 23700.4968 - val_loss: 19711.2351\n",
      "Epoch 162/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 23521.9805 - val_loss: 19353.0765\n",
      "Epoch 163/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 23289.4974 - val_loss: 18495.0024\n",
      "Epoch 164/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 23146.1177 - val_loss: 18525.8958\n",
      "Epoch 165/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 23378.2289 - val_loss: 18674.6753\n",
      "Epoch 166/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 22990.6150 - val_loss: 18405.3405\n",
      "Epoch 167/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 23208.1085 - val_loss: 18444.8079\n",
      "Epoch 168/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 23341.9950 - val_loss: 18214.6930\n",
      "Epoch 169/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22968.4293 - val_loss: 18287.0789\n",
      "Epoch 170/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 23336.9285 - val_loss: 19328.6353\n",
      "Epoch 171/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 23004.5811 - val_loss: 22645.0320\n",
      "Epoch 172/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 23450.7607 - val_loss: 18237.4190\n",
      "Epoch 173/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 23322.7922 - val_loss: 18528.1455\n",
      "Epoch 174/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 22646.3451 - val_loss: 18115.4026\n",
      "Epoch 175/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 22568.9873 - val_loss: 19539.2561\n",
      "Epoch 176/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 23544.2008 - val_loss: 17933.2717\n",
      "Epoch 177/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 22497.0116 - val_loss: 17354.5006\n",
      "Epoch 178/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 22879.9811 - val_loss: 17579.1927\n",
      "Epoch 179/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22938.6665 - val_loss: 18413.8741\n",
      "Epoch 180/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22665.2603 - val_loss: 19428.7250\n",
      "Epoch 181/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 22319.2484 - val_loss: 17366.1969\n",
      "Epoch 182/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 22669.5232 - val_loss: 18838.8342\n",
      "Epoch 183/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 22451.1597 - val_loss: 18472.8874\n",
      "Epoch 184/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 22706.7617 - val_loss: 18255.4424\n",
      "Epoch 185/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22957.0078 - val_loss: 17473.3416\n",
      "Epoch 186/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22531.9464 - val_loss: 16844.6493\n",
      "Epoch 187/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 22240.5742 - val_loss: 17564.5887\n",
      "Epoch 188/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 22642.6283 - val_loss: 17112.6908\n",
      "Epoch 189/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 22320.6819 - val_loss: 17639.8543\n",
      "Epoch 190/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22117.3255 - val_loss: 17005.3269\n",
      "Epoch 191/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22249.5553 - val_loss: 18395.3013\n",
      "Epoch 192/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 22401.0267 - val_loss: 16680.4410\n",
      "Epoch 193/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 22384.8159 - val_loss: 17162.2615\n",
      "Epoch 194/1000\n",
      "2304/2304 [==============================] - 1s 475us/step - loss: 21983.3552 - val_loss: 18605.2577\n",
      "Epoch 195/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22257.2526 - val_loss: 17034.5954\n",
      "Epoch 196/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 22122.9456 - val_loss: 17328.9022\n",
      "Epoch 197/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 22467.4348 - val_loss: 17312.1251\n",
      "Epoch 198/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 22034.0424 - val_loss: 16346.6881\n",
      "Epoch 199/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 21772.8173 - val_loss: 16449.1762\n",
      "Epoch 200/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 21616.0995 - val_loss: 19556.2224\n",
      "Epoch 201/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 22326.2749 - val_loss: 16196.6720\n",
      "Epoch 202/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 22678.2432 - val_loss: 16400.9500\n",
      "Epoch 203/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 21954.1421 - val_loss: 17115.8815\n",
      "Epoch 204/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21574.3031 - val_loss: 16127.1571\n",
      "Epoch 205/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 22338.9508 - val_loss: 19444.3208\n",
      "Epoch 206/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21852.7934 - val_loss: 19308.3233\n",
      "Epoch 207/1000\n",
      "2304/2304 [==============================] - 1s 473us/step - loss: 21872.5774 - val_loss: 17685.5849\n",
      "Epoch 208/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 21486.7361 - val_loss: 16639.5072\n",
      "Epoch 209/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 21571.2908 - val_loss: 16761.9651\n",
      "Epoch 210/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 21631.3609 - val_loss: 15658.4923\n",
      "Epoch 211/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 21486.4054 - val_loss: 15814.1505\n",
      "Epoch 212/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21541.5087 - val_loss: 17495.6494\n",
      "Epoch 213/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 22039.3132 - val_loss: 18907.8804\n",
      "Epoch 214/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21535.5008 - val_loss: 16334.5270\n",
      "Epoch 215/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 21397.5464 - val_loss: 15527.8804\n",
      "Epoch 216/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20970.6127 - val_loss: 15893.2644\n",
      "Epoch 217/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 21382.1890 - val_loss: 16356.3695\n",
      "Epoch 218/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21161.6115 - val_loss: 17358.3467\n",
      "Epoch 219/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 21313.9134 - val_loss: 16149.4819\n",
      "Epoch 220/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21500.9419 - val_loss: 15796.3191\n",
      "Epoch 221/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 21536.2349 - val_loss: 15471.1339\n",
      "Epoch 222/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 21088.8941 - val_loss: 15343.0244\n",
      "Epoch 223/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 21667.5794 - val_loss: 17580.5199\n",
      "Epoch 224/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 20965.1858 - val_loss: 15803.6322\n",
      "Epoch 225/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21442.6807 - val_loss: 17598.5028\n",
      "Epoch 226/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 21107.7338 - val_loss: 15927.4279\n",
      "Epoch 227/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20982.8748 - val_loss: 16270.2747\n",
      "Epoch 228/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21420.9400 - val_loss: 15423.4538\n",
      "Epoch 229/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 20855.8819 - val_loss: 16644.8780\n",
      "Epoch 230/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 20768.6303 - val_loss: 15575.5588\n",
      "Epoch 231/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21261.2271 - val_loss: 16437.3966\n",
      "Epoch 232/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 21497.1832 - val_loss: 15420.6945\n",
      "Epoch 233/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 20544.3840 - val_loss: 15224.6794\n",
      "Epoch 234/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21233.0104 - val_loss: 15038.2329\n",
      "Epoch 235/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21491.5446 - val_loss: 17434.5473\n",
      "Epoch 236/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 21326.1712 - val_loss: 16683.8884\n",
      "Epoch 237/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 21116.4700 - val_loss: 15612.9380\n",
      "Epoch 238/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22033.4280 - val_loss: 15167.3380\n",
      "Epoch 239/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21327.5555 - val_loss: 15373.3279\n",
      "Epoch 240/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 20829.2319 - val_loss: 15861.8656\n",
      "Epoch 241/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 20925.8254 - val_loss: 15428.4299\n",
      "Epoch 242/1000\n",
      "2304/2304 [==============================] - 1s 510us/step - loss: 21137.2842 - val_loss: 19346.3964\n",
      "Epoch 243/1000\n",
      "2304/2304 [==============================] - 1s 495us/step - loss: 20912.4358 - val_loss: 15086.4801\n",
      "Epoch 244/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 20783.2399 - val_loss: 17047.4020\n",
      "Epoch 245/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 20600.0964 - val_loss: 16235.3380\n",
      "Epoch 246/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20756.1085 - val_loss: 15630.0819\n",
      "Epoch 247/1000\n",
      "2304/2304 [==============================] - 1s 487us/step - loss: 20794.2793 - val_loss: 15813.6791\n",
      "Epoch 248/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 20578.2091 - val_loss: 14941.2435\n",
      "Epoch 249/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20526.0308 - val_loss: 17806.7003\n",
      "Epoch 250/1000\n",
      "2304/2304 [==============================] - 1s 583us/step - loss: 20334.8256 - val_loss: 18193.9887\n",
      "Epoch 251/1000\n",
      "2304/2304 [==============================] - 1s 530us/step - loss: 20293.9275 - val_loss: 17792.9437\n",
      "Epoch 252/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 20567.1465 - val_loss: 15440.0669\n",
      "Epoch 253/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 20427.0153 - val_loss: 14923.4824\n",
      "Epoch 254/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 20450.5625 - val_loss: 16042.9484\n",
      "Epoch 255/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 20198.3318 - val_loss: 16222.9939\n",
      "Epoch 256/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 20533.8341 - val_loss: 16831.9639\n",
      "Epoch 257/1000\n",
      "2304/2304 [==============================] - 1s 509us/step - loss: 20154.9191 - val_loss: 14754.8845\n",
      "Epoch 258/1000\n",
      "2304/2304 [==============================] - 1s 469us/step - loss: 20387.4427 - val_loss: 15878.7856\n",
      "Epoch 259/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 20359.2988 - val_loss: 16003.4819\n",
      "Epoch 260/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 20531.9542 - val_loss: 16200.7362\n",
      "Epoch 261/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 20018.3629 - val_loss: 15491.6521\n",
      "Epoch 262/1000\n",
      "2304/2304 [==============================] - 1s 481us/step - loss: 20267.9428 - val_loss: 15069.8928\n",
      "Epoch 263/1000\n",
      "2304/2304 [==============================] - 1s 479us/step - loss: 20530.1369 - val_loss: 15627.3145\n",
      "Epoch 264/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 20294.7257 - val_loss: 17765.7470\n",
      "Epoch 265/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 20360.8740 - val_loss: 14508.3821\n",
      "Epoch 266/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 20267.8221 - val_loss: 15420.8517\n",
      "Epoch 267/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 19862.5230 - val_loss: 14701.4737\n",
      "Epoch 268/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 19815.6728 - val_loss: 14743.0286\n",
      "Epoch 269/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19757.1898 - val_loss: 16036.5053\n",
      "Epoch 270/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 19572.5032 - val_loss: 15336.2828\n",
      "Epoch 271/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19700.6566 - val_loss: 15040.9445\n",
      "Epoch 272/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19473.6894 - val_loss: 15602.6384\n",
      "Epoch 273/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 19906.8170 - val_loss: 14509.2126\n",
      "Epoch 274/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 19699.7736 - val_loss: 15772.0936\n",
      "Epoch 275/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 20105.0729 - val_loss: 14584.7437\n",
      "Epoch 276/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 20147.8612 - val_loss: 15057.5087\n",
      "Epoch 277/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 19881.5120 - val_loss: 18572.5668\n",
      "Epoch 278/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19517.4842 - val_loss: 16397.4856\n",
      "Epoch 279/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 19976.7596 - val_loss: 15108.0453\n",
      "Epoch 280/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 19935.8306 - val_loss: 15692.7591\n",
      "Epoch 281/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 19793.6322 - val_loss: 14389.2686\n",
      "Epoch 282/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19412.6952 - val_loss: 15312.0001\n",
      "Epoch 283/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 20059.2136 - val_loss: 15273.2969\n",
      "Epoch 284/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19604.2384 - val_loss: 14420.2558\n",
      "Epoch 285/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 19496.6790 - val_loss: 14708.9673\n",
      "Epoch 286/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 20049.3460 - val_loss: 16034.7254\n",
      "Epoch 287/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 19478.0735 - val_loss: 14571.8502\n",
      "Epoch 288/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19667.3767 - val_loss: 14611.5370\n",
      "Epoch 289/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19504.3439 - val_loss: 14015.6003\n",
      "Epoch 290/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19758.8318 - val_loss: 16997.5221\n",
      "Epoch 291/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 19601.7732 - val_loss: 17615.9217\n",
      "Epoch 292/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 19661.4567 - val_loss: 16816.5259\n",
      "Epoch 293/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19131.7665 - val_loss: 14086.0776\n",
      "Epoch 294/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 19576.5483 - val_loss: 14701.9938\n",
      "Epoch 295/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 19444.5205 - val_loss: 14263.2803\n",
      "Epoch 296/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 19304.4485 - val_loss: 14911.7827\n",
      "Epoch 297/1000\n",
      "2304/2304 [==============================] - 2s 687us/step - loss: 19703.8128 - val_loss: 16053.4814\n",
      "Epoch 298/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 19346.9465 - val_loss: 14261.0299\n",
      "Epoch 299/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 19704.9612 - val_loss: 14267.3405\n",
      "Epoch 300/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 19352.9026 - val_loss: 14148.4302\n",
      "Epoch 301/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 19498.7444 - val_loss: 14138.5259\n",
      "Epoch 302/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18726.3407 - val_loss: 15887.5956\n",
      "Epoch 303/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 19946.6447 - val_loss: 16257.2649\n",
      "Epoch 304/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 19362.7704 - val_loss: 13983.4914\n",
      "Epoch 305/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 18790.8474 - val_loss: 14023.9126\n",
      "Epoch 306/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19160.9730 - val_loss: 14827.6932\n",
      "Epoch 307/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19190.6534 - val_loss: 18906.2787\n",
      "Epoch 308/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 19401.0639 - val_loss: 14333.4869\n",
      "Epoch 309/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19238.1993 - val_loss: 19174.5764\n",
      "Epoch 310/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 20029.8387 - val_loss: 14179.8829\n",
      "Epoch 311/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 18918.1769 - val_loss: 15346.9258\n",
      "Epoch 312/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19041.3360 - val_loss: 15424.8321\n",
      "Epoch 313/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19119.5293 - val_loss: 14270.7577\n",
      "Epoch 314/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 19292.8256 - val_loss: 14625.2434\n",
      "Epoch 315/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 19020.3923 - val_loss: 15541.8373\n",
      "Epoch 316/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19109.0529 - val_loss: 14618.3543\n",
      "Epoch 317/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18554.5315 - val_loss: 14239.7411\n",
      "Epoch 318/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19012.3046 - val_loss: 14200.9190\n",
      "Epoch 319/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18846.4739 - val_loss: 14101.2692\n",
      "Epoch 320/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 18813.7599 - val_loss: 14046.8665\n",
      "Epoch 321/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18852.2364 - val_loss: 15203.3614\n",
      "Epoch 322/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 19056.3984 - val_loss: 14890.5568\n",
      "Epoch 323/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 18563.3026 - val_loss: 13836.5927\n",
      "Epoch 324/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 19340.7887 - val_loss: 14266.8893\n",
      "Epoch 325/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 19060.3305 - val_loss: 15360.9089\n",
      "Epoch 326/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18662.2458 - val_loss: 14017.1838\n",
      "Epoch 327/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 18428.4088 - val_loss: 14745.7661\n",
      "Epoch 328/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 19135.0274 - val_loss: 15207.9820\n",
      "Epoch 329/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18923.7394 - val_loss: 14965.7481\n",
      "Epoch 330/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 18535.9474 - val_loss: 17499.9861\n",
      "Epoch 331/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 19013.6725 - val_loss: 15235.5978\n",
      "Epoch 332/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 18596.5386 - val_loss: 15663.1766\n",
      "Epoch 333/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 18753.9279 - val_loss: 14441.8432\n",
      "Epoch 334/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18830.9042 - val_loss: 14302.3303\n",
      "Epoch 335/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18712.8998 - val_loss: 14407.8947\n",
      "Epoch 336/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18339.9842 - val_loss: 16368.5578\n",
      "Epoch 337/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 18322.5995 - val_loss: 14554.7695\n",
      "Epoch 338/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18302.4392 - val_loss: 18285.9036\n",
      "Epoch 339/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 18712.5002 - val_loss: 16307.5702\n",
      "Epoch 340/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18290.9863 - val_loss: 14239.9206\n",
      "Epoch 341/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18704.4309 - val_loss: 14550.0324\n",
      "Epoch 342/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18247.0918 - val_loss: 14879.0659\n",
      "Epoch 343/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 18006.7334 - val_loss: 18404.3097\n",
      "Epoch 344/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 18743.3766 - val_loss: 14351.7088\n",
      "Epoch 345/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 18354.7083 - val_loss: 13809.4760\n",
      "Epoch 346/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 18344.7377 - val_loss: 14164.0234\n",
      "Epoch 347/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17953.9372 - val_loss: 15203.0973\n",
      "Epoch 348/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 18169.8337 - val_loss: 15557.0146\n",
      "Epoch 349/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 18846.4769 - val_loss: 13736.5097\n",
      "Epoch 350/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 18310.2781 - val_loss: 15919.4781\n",
      "Epoch 351/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17808.3110 - val_loss: 16368.7301\n",
      "Epoch 352/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18350.3996 - val_loss: 14352.2247\n",
      "Epoch 353/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 18125.6151 - val_loss: 14588.8044\n",
      "Epoch 354/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17982.2255 - val_loss: 15111.4960\n",
      "Epoch 355/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 18200.9428 - val_loss: 16779.2044\n",
      "Epoch 356/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17829.2466 - val_loss: 15074.7010\n",
      "Epoch 357/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 18016.9196 - val_loss: 14864.5632\n",
      "Epoch 358/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 17915.1799 - val_loss: 24316.4935\n",
      "Epoch 359/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19223.4313 - val_loss: 14180.9230\n",
      "Epoch 360/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 18647.8201 - val_loss: 13863.6924\n",
      "Epoch 361/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 18664.2566 - val_loss: 15385.2874\n",
      "Epoch 362/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17911.7704 - val_loss: 14680.4609\n",
      "Epoch 363/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 17927.6700 - val_loss: 14011.2587\n",
      "Epoch 364/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 17879.9066 - val_loss: 14464.9448\n",
      "Epoch 365/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18198.5349 - val_loss: 15854.3383\n",
      "Epoch 366/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17806.2551 - val_loss: 16639.1137\n",
      "Epoch 367/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17713.9328 - val_loss: 15978.6447\n",
      "Epoch 368/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18191.1775 - val_loss: 13860.3972\n",
      "Epoch 369/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 17839.4774 - val_loss: 16243.3496\n",
      "Epoch 370/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18056.7944 - val_loss: 13988.9696\n",
      "Epoch 371/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17830.5053 - val_loss: 13991.4631\n",
      "Epoch 372/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 17826.4593 - val_loss: 14288.8727\n",
      "Epoch 373/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18230.0502 - val_loss: 13970.4442\n",
      "Epoch 374/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18149.2701 - val_loss: 13912.5779\n",
      "Epoch 375/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17991.8544 - val_loss: 14408.1569\n",
      "Epoch 376/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17852.9588 - val_loss: 13976.1019\n",
      "Epoch 377/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17220.9854 - val_loss: 14601.7443\n",
      "Epoch 378/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 18052.9831 - val_loss: 14810.8670\n",
      "Epoch 379/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 17936.4085 - val_loss: 15385.9314\n",
      "Epoch 380/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17604.2571 - val_loss: 22286.7142\n",
      "Epoch 381/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18617.3345 - val_loss: 16034.6185\n",
      "Epoch 382/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17403.8869 - val_loss: 14999.4376\n",
      "Epoch 383/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17939.8127 - val_loss: 14766.4007\n",
      "Epoch 384/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 18240.0339 - val_loss: 14057.3904\n",
      "Epoch 385/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 17869.7416 - val_loss: 17336.3759\n",
      "Epoch 386/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17826.6345 - val_loss: 15285.4909\n",
      "Epoch 387/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17667.2922 - val_loss: 14430.3984\n",
      "Epoch 388/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 17571.7256 - val_loss: 14216.6904\n",
      "Epoch 389/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 17352.5210 - val_loss: 13842.0403\n",
      "Epoch 390/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17804.1591 - val_loss: 14489.6196\n",
      "Epoch 391/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17290.5272 - val_loss: 15556.0982\n",
      "Epoch 392/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17562.2438 - val_loss: 14057.2289\n",
      "Epoch 393/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17475.4925 - val_loss: 14393.1716\n",
      "Epoch 394/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 17683.2711 - val_loss: 13867.6408\n",
      "Epoch 395/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18206.1145 - val_loss: 14119.2243\n",
      "Epoch 396/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17573.8009 - val_loss: 14654.6191\n",
      "Epoch 397/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17220.1603 - val_loss: 17501.2350\n",
      "Epoch 398/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17444.1953 - val_loss: 15443.5200\n",
      "Epoch 399/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17212.9262 - val_loss: 14271.1408\n",
      "Epoch 400/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18024.3335 - val_loss: 14294.3726\n",
      "Epoch 401/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17486.2469 - val_loss: 13969.2431\n",
      "Epoch 402/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17356.3129 - val_loss: 14932.2968\n",
      "Epoch 403/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17733.6313 - val_loss: 15349.2541\n",
      "Epoch 404/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17096.2496 - val_loss: 14960.6332\n",
      "Epoch 405/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17120.7252 - val_loss: 14787.6082\n",
      "Epoch 406/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 17491.6736 - val_loss: 19178.5432\n",
      "Epoch 407/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17724.7867 - val_loss: 14122.0443\n",
      "Epoch 408/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17579.8739 - val_loss: 14003.0985\n",
      "Epoch 409/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17608.8391 - val_loss: 17843.3101\n",
      "Epoch 410/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17523.1099 - val_loss: 14959.4707\n",
      "Epoch 411/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16910.8874 - val_loss: 13747.2737\n",
      "Epoch 412/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17539.3152 - val_loss: 14720.9098\n",
      "Epoch 413/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17267.5506 - val_loss: 14258.4516\n",
      "Epoch 414/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17315.9268 - val_loss: 13593.2258\n",
      "Epoch 415/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17380.5531 - val_loss: 14079.7826\n",
      "Epoch 416/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16996.8228 - val_loss: 15113.6179\n",
      "Epoch 417/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17600.8175 - val_loss: 18986.0353\n",
      "Epoch 418/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17023.1818 - val_loss: 14341.5397\n",
      "Epoch 419/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17573.1886 - val_loss: 14370.9430\n",
      "Epoch 420/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17225.8739 - val_loss: 15407.3638\n",
      "Epoch 421/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17412.0493 - val_loss: 19036.0672\n",
      "Epoch 422/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17108.0607 - val_loss: 15606.9727\n",
      "Epoch 423/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17136.4948 - val_loss: 15391.9444\n",
      "Epoch 424/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17093.5108 - val_loss: 14448.2228\n",
      "Epoch 425/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16837.8037 - val_loss: 16118.2474\n",
      "Epoch 426/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17296.2004 - val_loss: 13944.9400\n",
      "Epoch 427/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17272.2626 - val_loss: 13772.1651\n",
      "Epoch 428/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17281.5558 - val_loss: 13642.4159\n",
      "Epoch 429/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17101.2987 - val_loss: 15898.3358\n",
      "Epoch 430/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16709.3143 - val_loss: 19334.2600\n",
      "Epoch 431/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 16868.6854 - val_loss: 16250.8959\n",
      "Epoch 432/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17385.3112 - val_loss: 13705.7346\n",
      "Epoch 433/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17247.9291 - val_loss: 14623.1077\n",
      "Epoch 434/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17188.4737 - val_loss: 13852.3366\n",
      "Epoch 435/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16656.4663 - val_loss: 14797.9058\n",
      "Epoch 436/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 17156.8052 - val_loss: 13735.2475\n",
      "Epoch 437/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 17050.5127 - val_loss: 17040.0685\n",
      "Epoch 438/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16785.3803 - val_loss: 15292.6484\n",
      "Epoch 439/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16491.9697 - val_loss: 15786.6080\n",
      "Epoch 440/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17464.6337 - val_loss: 15852.0196\n",
      "Epoch 441/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17213.6505 - val_loss: 15082.6042\n",
      "Epoch 442/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17345.8611 - val_loss: 14912.8041\n",
      "Epoch 443/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16981.0900 - val_loss: 18065.5751\n",
      "Epoch 444/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 17532.0109 - val_loss: 16386.4432\n",
      "Epoch 445/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17591.5213 - val_loss: 14487.9600\n",
      "Epoch 446/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17624.2621 - val_loss: 16752.8077\n",
      "Epoch 447/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16998.9168 - val_loss: 13496.9836\n",
      "Epoch 448/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 16836.7056 - val_loss: 14631.2539\n",
      "Epoch 449/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16696.3389 - val_loss: 16631.2494\n",
      "Epoch 450/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16983.9090 - val_loss: 15312.0523\n",
      "Epoch 451/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16810.2610 - val_loss: 14278.9533\n",
      "Epoch 452/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17404.3263 - val_loss: 15086.4043\n",
      "Epoch 453/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17100.2959 - val_loss: 13936.6329\n",
      "Epoch 454/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16667.1507 - val_loss: 18293.9448\n",
      "Epoch 455/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 17168.9288- ETA: 0s - - 1s 438us/step - loss: 17086.7000 - val_loss: 13579.2260\n",
      "Epoch 456/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16701.5239 - val_loss: 14569.9128\n",
      "Epoch 457/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16879.7268 - val_loss: 13863.3398\n",
      "Epoch 458/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 16426.4349 - val_loss: 17490.6424\n",
      "Epoch 459/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 17047.0664 - val_loss: 14906.5276\n",
      "Epoch 460/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 17470.8861 - val_loss: 14052.3652\n",
      "Epoch 461/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16674.0154 - val_loss: 17727.5517\n",
      "Epoch 462/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17145.5984 - val_loss: 14692.3786\n",
      "Epoch 463/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17166.9755 - val_loss: 14124.9136\n",
      "Epoch 464/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16679.6169 - val_loss: 19373.4150\n",
      "Epoch 465/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 16774.5541 - val_loss: 14200.0199\n",
      "Epoch 466/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16595.9005 - val_loss: 14423.6457\n",
      "Epoch 467/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16689.2204 - val_loss: 14240.4985\n",
      "Epoch 468/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16708.0954 - val_loss: 14334.9017\n",
      "Epoch 469/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 17191.4972 - val_loss: 13775.6621\n",
      "Epoch 470/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17505.5673 - val_loss: 13765.9852\n",
      "Epoch 471/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 17377.3753 - val_loss: 16874.4895\n",
      "Epoch 472/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16932.0075 - val_loss: 15280.1072\n",
      "Epoch 473/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16530.4014 - val_loss: 14520.9200\n",
      "Epoch 474/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17395.5364 - val_loss: 13848.9501\n",
      "Epoch 475/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16857.5059 - val_loss: 13565.6380\n",
      "Epoch 476/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 16767.7075 - val_loss: 19872.7868\n",
      "Epoch 477/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16884.9123 - val_loss: 13176.7210\n",
      "Epoch 478/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16330.7191 - val_loss: 14813.3151\n",
      "Epoch 479/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 16560.1846 - val_loss: 13560.4959\n",
      "Epoch 480/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 16994.8374 - val_loss: 13748.0220\n",
      "Epoch 481/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 17105.0768 - val_loss: 13977.5572\n",
      "Epoch 482/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 16926.7186 - val_loss: 15421.4735\n",
      "Epoch 483/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 17416.383 - 1s 442us/step - loss: 17520.7117 - val_loss: 14974.8713\n",
      "Epoch 484/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17241.7099 - val_loss: 16109.2987\n",
      "Epoch 485/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 16878.6128 - val_loss: 13340.2037\n",
      "Epoch 486/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 16567.2597 - val_loss: 13226.7989\n",
      "Epoch 487/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17009.0485 - val_loss: 14334.8273\n",
      "Epoch 488/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17224.3196 - val_loss: 15182.8221\n",
      "Epoch 489/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16113.3428 - val_loss: 14707.3002\n",
      "Epoch 490/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16157.4614 - val_loss: 17262.7748\n",
      "Epoch 491/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16754.3682 - val_loss: 17514.4146\n",
      "Epoch 492/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16435.4573 - val_loss: 13711.0666\n",
      "Epoch 493/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17039.9159 - val_loss: 15920.7148\n",
      "Epoch 494/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16618.5890 - val_loss: 13543.7893\n",
      "Epoch 495/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17146.2448 - val_loss: 18693.5495\n",
      "Epoch 496/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16916.5060 - val_loss: 13491.6188\n",
      "Epoch 497/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16322.7569 - val_loss: 14055.7516\n",
      "Epoch 498/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16738.7356 - val_loss: 13729.1235\n",
      "Epoch 499/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17037.1458 - val_loss: 19032.3017\n",
      "Epoch 500/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17037.1399 - val_loss: 13309.6670\n",
      "Epoch 501/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16405.3647 - val_loss: 13464.1638\n",
      "Epoch 502/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 17211.2725 - val_loss: 17083.4213\n",
      "Epoch 503/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 17172.4802 - val_loss: 13478.5523\n",
      "Epoch 504/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16247.5303 - val_loss: 14198.8873\n",
      "Epoch 505/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16671.5918 - val_loss: 13535.8521\n",
      "Epoch 506/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16185.6086 - val_loss: 14095.6265\n",
      "Epoch 507/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16207.7347 - val_loss: 14325.4418\n",
      "Epoch 508/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16652.1647 - val_loss: 14851.3673\n",
      "Epoch 509/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 16606.8829 - val_loss: 14483.6561\n",
      "Epoch 510/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16154.6917 - val_loss: 13027.8321\n",
      "Epoch 511/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 16352.7531 - val_loss: 13074.6578\n",
      "Epoch 512/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16269.5398 - val_loss: 15614.6946\n",
      "Epoch 513/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16844.1695 - val_loss: 13532.4958\n",
      "Epoch 514/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16391.5720 - val_loss: 13839.0900\n",
      "Epoch 515/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16910.4774 - val_loss: 13006.5320\n",
      "Epoch 516/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16441.9044 - val_loss: 13741.3823\n",
      "Epoch 517/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16175.2031 - val_loss: 13118.6830\n",
      "Epoch 518/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16029.5415 - val_loss: 13535.7123\n",
      "Epoch 519/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16822.5800 - val_loss: 12918.1999\n",
      "Epoch 520/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16400.1417 - val_loss: 13436.6186\n",
      "Epoch 521/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 16581.6498 - val_loss: 13149.8857\n",
      "Epoch 522/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16398.8991 - val_loss: 13370.1782\n",
      "Epoch 523/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16296.1482 - val_loss: 16340.5884\n",
      "Epoch 524/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16327.9647 - val_loss: 13298.2406\n",
      "Epoch 525/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16280.1426 - val_loss: 13291.0479\n",
      "Epoch 526/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16098.8848 - val_loss: 13626.7445\n",
      "Epoch 527/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16265.7438 - val_loss: 13826.5380\n",
      "Epoch 528/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15989.9011 - val_loss: 14713.3395\n",
      "Epoch 529/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15569.1148 - val_loss: 13209.5831\n",
      "Epoch 530/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16541.1532 - val_loss: 17341.2461\n",
      "Epoch 531/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16239.2389 - val_loss: 13829.2114\n",
      "Epoch 532/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16521.4224 - val_loss: 15856.1819\n",
      "Epoch 533/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15968.5748 - val_loss: 12955.7784\n",
      "Epoch 534/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 16293.7703 - val_loss: 13159.6920\n",
      "Epoch 535/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15915.4719 - val_loss: 15236.5337\n",
      "Epoch 536/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16546.5183 - val_loss: 16853.1425\n",
      "Epoch 537/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16415.3709 - val_loss: 22590.1958\n",
      "Epoch 538/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16038.1731 - val_loss: 15478.0320\n",
      "Epoch 539/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16662.2867 - val_loss: 13633.4050\n",
      "Epoch 540/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16813.9251 - val_loss: 12660.4432\n",
      "Epoch 541/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 16527.9992 - val_loss: 14913.9604\n",
      "Epoch 542/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 16079.3291 - val_loss: 13788.1918\n",
      "Epoch 543/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16225.2902 - val_loss: 14426.3797\n",
      "Epoch 544/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 15732.6024 - val_loss: 13636.5850\n",
      "Epoch 545/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16214.2543 - val_loss: 21259.3888\n",
      "Epoch 546/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 16336.5275 - val_loss: 13642.9841\n",
      "Epoch 547/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16242.7494 - val_loss: 12891.3443\n",
      "Epoch 548/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15609.3064 - val_loss: 15241.3289\n",
      "Epoch 549/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 16055.6001 - val_loss: 15129.6870\n",
      "Epoch 550/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 16056.1482 - val_loss: 13194.1173\n",
      "Epoch 551/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16373.1419 - val_loss: 13835.9007\n",
      "Epoch 552/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 16585.9757 - val_loss: 15642.5804\n",
      "Epoch 553/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 16268.6899 - val_loss: 12619.5854\n",
      "Epoch 554/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16432.3227 - val_loss: 14910.7167\n",
      "Epoch 555/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15964.3666 - val_loss: 13346.9381\n",
      "Epoch 556/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15907.5030 - val_loss: 12983.0486\n",
      "Epoch 557/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15918.8584 - val_loss: 13650.5844\n",
      "Epoch 558/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16200.4612 - val_loss: 12951.2539\n",
      "Epoch 559/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15835.6661 - val_loss: 14813.2323\n",
      "Epoch 560/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16570.0578 - val_loss: 14454.0631\n",
      "Epoch 561/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16869.6169 - val_loss: 13610.7718\n",
      "Epoch 562/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16840.4261 - val_loss: 13181.9136\n",
      "Epoch 563/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15979.8033 - val_loss: 13446.4118\n",
      "Epoch 564/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15563.6671 - val_loss: 13199.9821\n",
      "Epoch 565/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15908.4225 - val_loss: 15984.1726\n",
      "Epoch 566/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16004.9399 - val_loss: 13905.7834\n",
      "Epoch 567/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16389.2974 - val_loss: 13452.7645\n",
      "Epoch 568/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15584.9971 - val_loss: 14775.5267\n",
      "Epoch 569/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15664.2811 - val_loss: 13648.0294\n",
      "Epoch 570/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16375.2549 - val_loss: 13240.0203\n",
      "Epoch 571/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15903.5278 - val_loss: 14575.3229\n",
      "Epoch 572/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16540.2915 - val_loss: 12986.2193\n",
      "Epoch 573/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15546.8738 - val_loss: 12724.5387\n",
      "Epoch 574/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15573.6981 - val_loss: 14370.9492\n",
      "Epoch 575/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15998.9777 - val_loss: 14381.9216\n",
      "Epoch 576/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 16236.6067 - val_loss: 13139.3926\n",
      "Epoch 577/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16401.3169 - val_loss: 12909.4291\n",
      "Epoch 578/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 15951.6085 - val_loss: 13372.4539\n",
      "Epoch 579/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15390.301 - 1s 447us/step - loss: 15447.2109 - val_loss: 16080.7027\n",
      "Epoch 580/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15932.6666 - val_loss: 13824.2292\n",
      "Epoch 581/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15664.1162 - val_loss: 14778.0713\n",
      "Epoch 582/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15933.7029 - val_loss: 13003.9517\n",
      "Epoch 583/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15956.3189 - val_loss: 16177.6614\n",
      "Epoch 584/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15874.3583 - val_loss: 13080.2921\n",
      "Epoch 585/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16791.4277 - val_loss: 14088.6852\n",
      "Epoch 586/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15705.0799 - val_loss: 18454.0310\n",
      "Epoch 587/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15808.1309 - val_loss: 16820.5833\n",
      "Epoch 588/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 16183.8922 - val_loss: 14711.2256\n",
      "Epoch 589/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15707.8248 - val_loss: 13111.5689\n",
      "Epoch 590/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16598.3475 - val_loss: 15295.8216\n",
      "Epoch 591/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15327.5790 - val_loss: 13901.1989\n",
      "Epoch 592/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15704.7646 - val_loss: 13032.4837\n",
      "Epoch 593/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15951.6286 - val_loss: 13004.5162\n",
      "Epoch 594/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 15690.0711 - val_loss: 12766.9858\n",
      "Epoch 595/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15764.8322 - val_loss: 14098.1799\n",
      "Epoch 596/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 16039.9761 - val_loss: 14123.3657\n",
      "Epoch 597/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16197.0552 - val_loss: 13257.4783\n",
      "Epoch 598/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15653.8917 - val_loss: 13044.1128\n",
      "Epoch 599/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 16027.9724 - val_loss: 14400.0111\n",
      "Epoch 600/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 15569.4053 - val_loss: 14585.1445\n",
      "Epoch 601/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16236.5629 - val_loss: 14213.7991\n",
      "Epoch 602/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15410.8726 - val_loss: 13744.9428\n",
      "Epoch 603/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15623.0107 - val_loss: 13769.4555\n",
      "Epoch 604/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15422.4580 - val_loss: 13720.9273\n",
      "Epoch 605/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15629.3536 - val_loss: 13780.4440\n",
      "Epoch 606/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15512.328 - 1s 449us/step - loss: 15667.5894 - val_loss: 15107.2038\n",
      "Epoch 607/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15842.8541 - val_loss: 15396.6564\n",
      "Epoch 608/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16343.3226 - val_loss: 16418.3831\n",
      "Epoch 609/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15627.2895 - val_loss: 13080.5057\n",
      "Epoch 610/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 16138.2899 - val_loss: 13839.8605\n",
      "Epoch 611/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15795.7646 - val_loss: 14323.5030\n",
      "Epoch 612/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16000.4406 - val_loss: 14379.4820\n",
      "Epoch 613/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15908.1178 - val_loss: 12850.5682\n",
      "Epoch 614/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16145.5608 - val_loss: 13584.1879\n",
      "Epoch 615/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15431.5824 - val_loss: 13392.1331\n",
      "Epoch 616/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16703.4658 - val_loss: 14792.3624\n",
      "Epoch 617/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15772.0554 - val_loss: 15436.8464\n",
      "Epoch 618/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15374.9280 - val_loss: 13229.2396\n",
      "Epoch 619/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15145.3295 - val_loss: 14809.5443\n",
      "Epoch 620/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15543.2908 - val_loss: 16547.6276\n",
      "Epoch 621/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15959.9643 - val_loss: 16376.9515\n",
      "Epoch 622/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15781.9054 - val_loss: 15017.2809\n",
      "Epoch 623/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15574.1608 - val_loss: 12977.8039\n",
      "Epoch 624/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15664.0746 - val_loss: 16512.8301\n",
      "Epoch 625/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15434.6600 - val_loss: 13110.2442\n",
      "Epoch 626/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15833.0265 - val_loss: 13771.7392\n",
      "Epoch 627/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15141.2832 - val_loss: 12895.8720\n",
      "Epoch 628/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15806.2560 - val_loss: 12599.8844\n",
      "Epoch 629/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 15253.5951 - val_loss: 15702.9138\n",
      "Epoch 630/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 16220.005 - 1s 446us/step - loss: 16211.7160 - val_loss: 13587.7423\n",
      "Epoch 631/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15374.0106 - val_loss: 16109.5302\n",
      "Epoch 632/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15973.8315 - val_loss: 14559.4370\n",
      "Epoch 633/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15757.8239 - val_loss: 14605.0098\n",
      "Epoch 634/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15382.4610 - val_loss: 15446.6752\n",
      "Epoch 635/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15981.6069 - val_loss: 14574.5966\n",
      "Epoch 636/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15255.1359 - val_loss: 16051.3238\n",
      "Epoch 637/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15448.6940 - val_loss: 13010.1859\n",
      "Epoch 638/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15537.2544 - val_loss: 14263.5028\n",
      "Epoch 639/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15717.0864 - val_loss: 13682.7131\n",
      "Epoch 640/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15358.8598 - val_loss: 13410.3975\n",
      "Epoch 641/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15642.4729 - val_loss: 13778.9329\n",
      "Epoch 642/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16350.4903 - val_loss: 21586.3186\n",
      "Epoch 643/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15697.2444 - val_loss: 13705.7611\n",
      "Epoch 644/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15046.5153 - val_loss: 16719.6757\n",
      "Epoch 645/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15784.5210 - val_loss: 13796.9106\n",
      "Epoch 646/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15669.4205 - val_loss: 12644.5263\n",
      "Epoch 647/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15642.5598 - val_loss: 13163.1053\n",
      "Epoch 648/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15469.4455 - val_loss: 14157.4993\n",
      "Epoch 649/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15148.3762 - val_loss: 12870.2361\n",
      "Epoch 650/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15614.2960 - val_loss: 12830.4788\n",
      "Epoch 651/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15455.5890 - val_loss: 14309.9376\n",
      "Epoch 652/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15504.0487 - val_loss: 12620.4909\n",
      "Epoch 653/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15521.0770 - val_loss: 13617.4397\n",
      "Epoch 654/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15487.8799 - val_loss: 13259.1685\n",
      "Epoch 655/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15204.8147 - val_loss: 13958.5722\n",
      "Epoch 656/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15702.2916 - val_loss: 13165.9372\n",
      "Epoch 657/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15200.5446 - val_loss: 14146.9903\n",
      "Epoch 658/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 15479.8287 - val_loss: 13355.3974\n",
      "Epoch 659/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15440.6843 - val_loss: 13331.1294\n",
      "Epoch 660/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 15174.4019 - val_loss: 12858.8573\n",
      "Epoch 661/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15110.9219 - val_loss: 12799.9921\n",
      "Epoch 662/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15598.324 - 1s 448us/step - loss: 15515.2419 - val_loss: 12942.6975\n",
      "Epoch 663/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16275.1000 - val_loss: 16717.4047\n",
      "Epoch 664/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16169.6125 - val_loss: 12684.8459\n",
      "Epoch 665/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15119.5771 - val_loss: 17778.7259\n",
      "Epoch 666/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15477.4023 - val_loss: 13685.2982\n",
      "Epoch 667/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15982.5753 - val_loss: 14503.3253\n",
      "Epoch 668/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15682.8486 - val_loss: 15272.2460\n",
      "Epoch 669/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15223.0342 - val_loss: 12861.6631\n",
      "Epoch 670/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 15199.3037 - val_loss: 12720.9584\n",
      "Epoch 671/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15367.5364 - val_loss: 12661.7466\n",
      "Epoch 672/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15171.9637 - val_loss: 13398.3861\n",
      "Epoch 673/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15272.5848 - val_loss: 13891.8174\n",
      "Epoch 674/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 15364.4168 - val_loss: 13129.6698\n",
      "Epoch 675/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15352.5513 - val_loss: 13137.0173\n",
      "Epoch 676/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15420.8494 - val_loss: 14306.8728\n",
      "Epoch 677/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15816.9606 - val_loss: 13225.2205\n",
      "Epoch 678/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15520.9441 - val_loss: 12961.2857\n",
      "Epoch 679/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16166.1388 - val_loss: 13093.5504\n",
      "Epoch 680/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15809.7020 - val_loss: 12755.8231\n",
      "Epoch 681/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15275.4096 - val_loss: 14574.4372\n",
      "Epoch 682/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15262.1467 - val_loss: 15008.6220\n",
      "Epoch 683/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15541.8515 - val_loss: 12507.0198\n",
      "Epoch 684/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 15458.2967 - val_loss: 12919.8445\n",
      "Epoch 685/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15089.8102 - val_loss: 13483.9403\n",
      "Epoch 686/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15078.7916 - val_loss: 13308.9251\n",
      "Epoch 687/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14969.1277 - val_loss: 15465.7025\n",
      "Epoch 688/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15335.7592 - val_loss: 12952.5697\n",
      "Epoch 689/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15527.9751 - val_loss: 17052.4783\n",
      "Epoch 690/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15339.5878 - val_loss: 14415.3618\n",
      "Epoch 691/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15469.8665 - val_loss: 14247.9914\n",
      "Epoch 692/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15702.3830 - val_loss: 17907.0751\n",
      "Epoch 693/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15765.4085 - val_loss: 13254.7512\n",
      "Epoch 694/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15332.0656 - val_loss: 18456.6299\n",
      "Epoch 695/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15447.8551 - val_loss: 12613.2257\n",
      "Epoch 696/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14687.8422 - val_loss: 13083.2457\n",
      "Epoch 697/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15330.3883 - val_loss: 18014.6404\n",
      "Epoch 698/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15781.9598 - val_loss: 16162.5326\n",
      "Epoch 699/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15493.8309 - val_loss: 17285.5977\n",
      "Epoch 700/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15423.0763 - val_loss: 12625.9207\n",
      "Epoch 701/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15297.0811 - val_loss: 13373.4003\n",
      "Epoch 702/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15426.0078 - val_loss: 13488.4394\n",
      "Epoch 703/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15466.9557 - val_loss: 14845.1572\n",
      "Epoch 704/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15065.8811 - val_loss: 12732.2395\n",
      "Epoch 705/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15026.7516 - val_loss: 13223.4333\n",
      "Epoch 706/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15230.2854 - val_loss: 14756.2749\n",
      "Epoch 707/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15406.9381 - val_loss: 13308.5025\n",
      "Epoch 708/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15260.3629 - val_loss: 18116.0258\n",
      "Epoch 709/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15283.3038 - val_loss: 13337.3922\n",
      "Epoch 710/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15137.5314 - val_loss: 13265.3038\n",
      "Epoch 711/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15759.4561 - val_loss: 14528.8233\n",
      "Epoch 712/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15241.5850 - val_loss: 12762.3783\n",
      "Epoch 713/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14968.4679 - val_loss: 13901.8424\n",
      "Epoch 714/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15471.8470 - val_loss: 13121.6925\n",
      "Epoch 715/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15340.8782 - val_loss: 16421.3447\n",
      "Epoch 716/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15203.0577 - val_loss: 13425.4123\n",
      "Epoch 717/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15364.1613 - val_loss: 14678.5288\n",
      "Epoch 718/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15190.8276 - val_loss: 13293.1317\n",
      "Epoch 719/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15485.2657 - val_loss: 16684.7799\n",
      "Epoch 720/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16062.7201 - val_loss: 12756.5438\n",
      "Epoch 721/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15582.1366 - val_loss: 13934.6589\n",
      "Epoch 722/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14930.4560 - val_loss: 14532.9120\n",
      "Epoch 723/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15068.7575 - val_loss: 12634.7672\n",
      "Epoch 724/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15363.4014 - val_loss: 13434.6976\n",
      "Epoch 725/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15257.4327 - val_loss: 18779.9918\n",
      "Epoch 726/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15877.7786 - val_loss: 13005.0797\n",
      "Epoch 727/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15261.8529 - val_loss: 12943.7489\n",
      "Epoch 728/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15631.8654 - val_loss: 12685.7935\n",
      "Epoch 729/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15082.9631 - val_loss: 12853.9259\n",
      "Epoch 730/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14789.6620 - val_loss: 13291.1079\n",
      "Epoch 731/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14779.1322 - val_loss: 12923.7221\n",
      "Epoch 732/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14957.5461 - val_loss: 14639.1517\n",
      "Epoch 733/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15424.5130 - val_loss: 12906.5334\n",
      "Epoch 734/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15092.7149 - val_loss: 12938.7308\n",
      "Epoch 735/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14993.9403 - val_loss: 13545.9049\n",
      "Epoch 736/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 14567.7017 - val_loss: 13553.1889\n",
      "Epoch 737/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 15193.0467 - val_loss: 16555.1944\n",
      "Epoch 738/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15208.2199 - val_loss: 13473.8713\n",
      "Epoch 739/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15558.0719 - val_loss: 13306.9156\n",
      "Epoch 740/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15205.8590 - val_loss: 13603.1274\n",
      "Epoch 741/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14711.1822 - val_loss: 17975.5598\n",
      "Epoch 742/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15439.0352 - val_loss: 18252.7317\n",
      "Epoch 743/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14858.0257 - val_loss: 13080.7335\n",
      "Epoch 744/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15334.4735 - val_loss: 12367.6314\n",
      "Epoch 745/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15592.4208 - val_loss: 12456.6742\n",
      "Epoch 746/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15372.3296 - val_loss: 13681.8867\n",
      "Epoch 747/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15552.5056 - val_loss: 13359.9924\n",
      "Epoch 748/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15025.2245 - val_loss: 13198.7190\n",
      "Epoch 749/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15587.6711 - val_loss: 13291.3897\n",
      "Epoch 750/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15234.3599 - val_loss: 13104.8654\n",
      "Epoch 751/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15286.4515 - val_loss: 13389.0263\n",
      "Epoch 752/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15011.1919 - val_loss: 13671.0663\n",
      "Epoch 753/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 14678.4676 - val_loss: 13171.7875\n",
      "Epoch 754/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 14898.6622 - val_loss: 16745.6186\n",
      "Epoch 755/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14864.0150 - val_loss: 14502.9875\n",
      "Epoch 756/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 14996.6706 - val_loss: 14170.1225\n",
      "Epoch 757/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14958.4556 - val_loss: 13103.1940\n",
      "Epoch 758/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14827.0645 - val_loss: 12728.4479\n",
      "Epoch 759/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15163.0861 - val_loss: 13287.7952\n",
      "Epoch 760/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14740.0526 - val_loss: 12897.9880\n",
      "Epoch 761/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14966.5553 - val_loss: 13621.3832\n",
      "Epoch 762/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14799.1578 - val_loss: 14286.3744\n",
      "Epoch 763/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14436.9415 - val_loss: 13498.1127\n",
      "Epoch 764/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15144.7726 - val_loss: 12865.2890\n",
      "Epoch 765/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15369.3907 - val_loss: 13159.7846\n",
      "Epoch 766/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14932.8306 - val_loss: 13319.9050\n",
      "Epoch 767/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14700.5915 - val_loss: 12496.0247\n",
      "Epoch 768/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14422.4766 - val_loss: 12903.3622\n",
      "Epoch 769/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 14772.8422 - val_loss: 12729.0690\n",
      "Epoch 770/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15411.607 - 1s 442us/step - loss: 15346.0232 - val_loss: 14042.6256\n",
      "Epoch 771/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15231.9011 - val_loss: 13969.7030\n",
      "Epoch 772/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15155.9134 - val_loss: 14454.8772\n",
      "Epoch 773/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 15267.4308 - val_loss: 13259.2004\n",
      "Epoch 774/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14596.1594 - val_loss: 13166.8524\n",
      "Epoch 775/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14974.0176 - val_loss: 15539.5823\n",
      "Epoch 776/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15169.9119 - val_loss: 13228.7943\n",
      "Epoch 777/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14630.1758 - val_loss: 13663.6288\n",
      "Epoch 778/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 14674.2638 - val_loss: 12558.5938\n",
      "Epoch 779/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14920.9787 - val_loss: 13532.3238\n",
      "Epoch 780/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 15182.5596 - val_loss: 15951.0021\n",
      "Epoch 781/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14665.4194 - val_loss: 12908.2029\n",
      "Epoch 782/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14690.0533 - val_loss: 14167.9302\n",
      "Epoch 783/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14653.5695 - val_loss: 17030.5262\n",
      "Epoch 784/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15122.4909 - val_loss: 12568.5641\n",
      "Epoch 785/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15265.6583 - val_loss: 12658.0560\n",
      "Epoch 786/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 14948.2878 - val_loss: 13892.8752\n",
      "Epoch 787/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14933.4436 - val_loss: 14457.1670\n",
      "Epoch 788/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15085.2040 - val_loss: 13747.4289\n",
      "Epoch 789/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15379.0492 - val_loss: 19403.6576\n",
      "Epoch 790/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 15351.0965 - val_loss: 15456.3321\n",
      "Epoch 791/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14805.4371 - val_loss: 12852.0827\n",
      "Epoch 792/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14794.1490 - val_loss: 12984.7817\n",
      "Epoch 793/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 14434.4702 - val_loss: 12845.6965\n",
      "Epoch 794/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 14672.0893 - val_loss: 13594.8156\n",
      "Epoch 795/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 14665.5351 - val_loss: 13367.0068\n",
      "Epoch 796/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14691.3304 - val_loss: 12902.3428\n",
      "Epoch 797/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15322.3794 - val_loss: 13206.3453\n",
      "Epoch 798/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14591.8013 - val_loss: 12691.5457\n",
      "Epoch 799/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14238.9320 - val_loss: 12883.0565\n",
      "Epoch 800/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14562.4019 - val_loss: 13239.7346\n",
      "Epoch 801/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14895.1009 - val_loss: 12925.1134\n",
      "Epoch 802/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14640.8927 - val_loss: 12759.0829\n",
      "Epoch 803/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14646.1457 - val_loss: 12718.9311\n",
      "Epoch 804/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14635.7928 - val_loss: 12636.7899\n",
      "Epoch 805/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 13996.3517 - val_loss: 14381.3851\n",
      "Epoch 806/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14318.8125 - val_loss: 15468.8791\n",
      "Epoch 807/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14880.0421 - val_loss: 13126.8431\n",
      "Epoch 808/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15080.8034 - val_loss: 14136.3962\n",
      "Epoch 809/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15469.5417 - val_loss: 12694.9700\n",
      "Epoch 810/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14256.0116 - val_loss: 12779.1585\n",
      "Epoch 811/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 15062.1193 - val_loss: 13845.3082\n",
      "Epoch 812/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14080.0018 - val_loss: 13449.0193\n",
      "Epoch 813/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14612.0249 - val_loss: 13226.6961\n",
      "Epoch 814/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14793.5876 - val_loss: 12672.4397\n",
      "Epoch 815/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14473.2528 - val_loss: 12693.7991\n",
      "Epoch 816/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 14533.8183 - val_loss: 13692.2471\n",
      "Epoch 817/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14729.4543 - val_loss: 13083.3531\n",
      "Epoch 818/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14497.7936 - val_loss: 13903.4400\n",
      "Epoch 819/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14109.7411 - val_loss: 13386.7339\n",
      "Epoch 820/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14994.6687 - val_loss: 14384.5567\n",
      "Epoch 821/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14667.1439 - val_loss: 16717.5792\n",
      "Epoch 822/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 15194.1799 - val_loss: 12673.5339\n",
      "Epoch 823/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14383.1840 - val_loss: 13179.6093\n",
      "Epoch 824/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14762.0785 - val_loss: 12920.0712\n",
      "Epoch 825/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14621.4354 - val_loss: 13191.5815\n",
      "Epoch 826/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14784.9669 - val_loss: 12863.7764\n",
      "Epoch 827/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14490.9969 - val_loss: 12752.3748\n",
      "Epoch 828/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14351.1834 - val_loss: 12576.6446\n",
      "Epoch 829/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 15036.8720 - val_loss: 12418.5804\n",
      "Epoch 830/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14464.0178 - val_loss: 12871.3090\n",
      "Epoch 831/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14654.7483 - val_loss: 13201.5221\n",
      "Epoch 832/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14462.2237 - val_loss: 13925.0163\n",
      "Epoch 833/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14949.5650 - val_loss: 13039.8272\n",
      "Epoch 834/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14270.4275 - val_loss: 12572.5281\n",
      "Epoch 835/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14900.3856 - val_loss: 12620.9649\n",
      "Epoch 836/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14709.6670 - val_loss: 12989.1388\n",
      "Epoch 837/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14657.4319 - val_loss: 13228.2369\n",
      "Epoch 838/1000\n",
      "2304/2304 [==============================] - 1s 472us/step - loss: 14724.9100 - val_loss: 12757.6617\n",
      "Epoch 839/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14601.4974 - val_loss: 12417.1430\n",
      "Epoch 840/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14986.3101 - val_loss: 17222.0426\n",
      "Epoch 841/1000\n",
      "2304/2304 [==============================] - 1s 411us/step - loss: 15089.0709 - val_loss: 12555.9500\n",
      "Epoch 842/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14993.7458 - val_loss: 14066.9829\n",
      "Epoch 843/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14532.6220 - val_loss: 18880.1531\n",
      "Epoch 844/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14584.9105 - val_loss: 13635.9832\n",
      "Epoch 845/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14396.5144 - val_loss: 12778.6250\n",
      "Epoch 846/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14060.4311 - val_loss: 13225.5006\n",
      "Epoch 847/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14654.3758 - val_loss: 13023.3650\n",
      "Epoch 848/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14654.8375 - val_loss: 13103.5657\n",
      "Epoch 849/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 14830.6239 - val_loss: 13058.2414\n",
      "Epoch 850/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14764.2105 - val_loss: 13815.4281\n",
      "Epoch 851/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14613.9552 - val_loss: 13237.9735\n",
      "Epoch 852/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14611.7756 - val_loss: 13520.5362\n",
      "Epoch 853/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14431.8364 - val_loss: 13894.3668\n",
      "Epoch 854/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 15137.1521 - val_loss: 22284.5248\n",
      "Epoch 855/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14813.4715 - val_loss: 13260.7255\n",
      "Epoch 856/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14475.8784 - val_loss: 13210.7836\n",
      "Epoch 857/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 14933.4577 - val_loss: 12749.1952\n",
      "Epoch 858/1000\n",
      "2304/2304 [==============================] - 1s 412us/step - loss: 14291.2518 - val_loss: 14971.0328\n",
      "Epoch 859/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15208.3715 - val_loss: 15258.7614\n",
      "Epoch 860/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14987.8951 - val_loss: 13586.2548\n",
      "Epoch 861/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14492.0720 - val_loss: 17675.6073\n",
      "Epoch 862/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 14506.5116 - val_loss: 12518.2817\n",
      "Epoch 863/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14188.5038 - val_loss: 13342.0729\n",
      "Epoch 864/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15359.8370 - val_loss: 16495.8379\n",
      "Epoch 865/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14965.1403 - val_loss: 13083.3793\n",
      "Epoch 866/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14175.7473 - val_loss: 13919.3206\n",
      "Epoch 867/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14389.9764 - val_loss: 13285.3221\n",
      "Epoch 868/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14221.4755 - val_loss: 16674.3418\n",
      "Epoch 869/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 13982.3276 - val_loss: 14725.3013\n",
      "Epoch 870/1000\n",
      "2304/2304 [==============================] - 1s 370us/step - loss: 14150.5493 - val_loss: 12991.6504\n",
      "Epoch 871/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14241.1971 - val_loss: 14242.6713\n",
      "Epoch 872/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 14235.1650 - val_loss: 13106.2846\n",
      "Epoch 873/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14888.9844 - val_loss: 13805.2642\n",
      "Epoch 874/1000\n",
      "2304/2304 [==============================] - 1s 380us/step - loss: 14627.0407 - val_loss: 13571.2920\n",
      "Epoch 875/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14100.9699 - val_loss: 13488.7944\n",
      "Epoch 876/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14497.7654 - val_loss: 12479.8602\n",
      "Epoch 877/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 14594.8237 - val_loss: 12449.0825\n",
      "Epoch 878/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14203.2660 - val_loss: 12609.4652\n",
      "Epoch 879/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14727.8350 - val_loss: 12740.9682\n",
      "Epoch 880/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14200.1342 - val_loss: 12994.0223\n",
      "Epoch 881/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 14441.8817 - val_loss: 16508.9571\n",
      "Epoch 882/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 14590.5564 - val_loss: 12704.1016\n",
      "Epoch 883/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14141.6053 - val_loss: 14625.2396\n",
      "Epoch 884/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14457.2792 - val_loss: 13181.9282\n",
      "Epoch 885/1000\n",
      "2304/2304 [==============================] - 1s 395us/step - loss: 14154.0893 - val_loss: 13142.0646\n",
      "Epoch 886/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14099.0075 - val_loss: 12615.8368\n",
      "Epoch 887/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14432.0832 - val_loss: 13688.7647\n",
      "Epoch 888/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14763.6511 - val_loss: 12546.1383\n",
      "Epoch 889/1000\n",
      "2304/2304 [==============================] - 1s 400us/step - loss: 14257.1427 - val_loss: 15314.1020\n",
      "Epoch 890/1000\n",
      "2304/2304 [==============================] - 1s 407us/step - loss: 14685.3420 - val_loss: 12802.6904\n",
      "Epoch 891/1000\n",
      "2304/2304 [==============================] - 1s 398us/step - loss: 14311.2269 - val_loss: 13009.1204\n",
      "Epoch 892/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14441.2347 - val_loss: 13246.5764\n",
      "Epoch 893/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 13962.6542 - val_loss: 13388.3987\n",
      "Epoch 894/1000\n",
      "2304/2304 [==============================] - 1s 403us/step - loss: 14644.0992 - val_loss: 16022.9132\n",
      "Epoch 895/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14487.1708 - val_loss: 13156.4069\n",
      "Epoch 896/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14494.2526 - val_loss: 12960.4321\n",
      "Epoch 897/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14206.2011 - val_loss: 13049.3552\n",
      "Epoch 898/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14461.0843 - val_loss: 13081.9360\n",
      "Epoch 899/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14231.0203 - val_loss: 12909.8227\n",
      "Epoch 900/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14248.6927 - val_loss: 15215.5780\n",
      "Epoch 901/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14475.0888 - val_loss: 12317.9968\n",
      "Epoch 902/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14409.6735 - val_loss: 12467.8517\n",
      "Epoch 903/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 14274.7537 - val_loss: 13747.5079\n",
      "Epoch 904/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14452.9215 - val_loss: 12402.7182\n",
      "Epoch 905/1000\n",
      "2304/2304 [==============================] - 1s 410us/step - loss: 14406.0842 - val_loss: 13519.5157\n",
      "Epoch 906/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14147.5470 - val_loss: 15100.2449\n",
      "Epoch 907/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14430.0315 - val_loss: 13061.8966\n",
      "Epoch 908/1000\n",
      "2304/2304 [==============================] - 1s 392us/step - loss: 14037.1031 - val_loss: 15047.8518\n",
      "Epoch 909/1000\n",
      "2304/2304 [==============================] - 1s 404us/step - loss: 14497.5600 - val_loss: 12198.8537\n",
      "Epoch 910/1000\n",
      "2304/2304 [==============================] - 1s 411us/step - loss: 14366.8323 - val_loss: 14644.8727\n",
      "Epoch 911/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14138.7617 - val_loss: 13198.3730\n",
      "Epoch 912/1000\n",
      "2304/2304 [==============================] - 1s 387us/step - loss: 14551.6633 - val_loss: 12640.6007\n",
      "Epoch 913/1000\n",
      "2304/2304 [==============================] - 1s 395us/step - loss: 13842.8162 - val_loss: 13103.7514\n",
      "Epoch 914/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 14027.096 - 1s 406us/step - loss: 14014.5653 - val_loss: 13519.0226\n",
      "Epoch 915/1000\n",
      "2304/2304 [==============================] - 1s 406us/step - loss: 14198.5005 - val_loss: 13368.7286\n",
      "Epoch 916/1000\n",
      "2304/2304 [==============================] - 1s 399us/step - loss: 14822.5560 - val_loss: 15374.5320\n",
      "Epoch 917/1000\n",
      "2304/2304 [==============================] - 1s 402us/step - loss: 14289.0921 - val_loss: 14090.4929\n",
      "Epoch 918/1000\n",
      "2304/2304 [==============================] - 1s 414us/step - loss: 14206.7270 - val_loss: 13044.4802\n",
      "Epoch 919/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14460.7795 - val_loss: 13302.6180\n",
      "Epoch 920/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 14155.9907 - val_loss: 13949.3602\n",
      "Epoch 921/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 14249.6631 - val_loss: 13610.0707\n",
      "Epoch 922/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 13840.5041 - val_loss: 13909.9199\n",
      "Epoch 923/1000\n",
      "2304/2304 [==============================] - 1s 417us/step - loss: 13814.5286 - val_loss: 12826.1274\n",
      "Epoch 924/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14904.2527 - val_loss: 13254.0662\n",
      "Epoch 925/1000\n",
      "2304/2304 [==============================] - 1s 401us/step - loss: 14411.9720 - val_loss: 12841.3170\n",
      "Epoch 926/1000\n",
      "2304/2304 [==============================] - 1s 406us/step - loss: 14629.6957 - val_loss: 15033.8485\n",
      "Epoch 927/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14348.2908 - val_loss: 14876.2320\n",
      "Epoch 928/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14075.3151 - val_loss: 13959.1821\n",
      "Epoch 929/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14288.5601 - val_loss: 12458.3268\n",
      "Epoch 930/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14819.0479 - val_loss: 12861.2873\n",
      "Epoch 931/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 13920.4318 - val_loss: 12759.2584\n",
      "Epoch 932/1000\n",
      "2304/2304 [==============================] - 1s 410us/step - loss: 14030.5567 - val_loss: 16690.3853\n",
      "Epoch 933/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14995.1577 - val_loss: 12408.4145\n",
      "Epoch 934/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14364.7210 - val_loss: 13108.9323\n",
      "Epoch 935/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14219.7713 - val_loss: 12570.9672\n",
      "Epoch 936/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14441.0540 - val_loss: 12885.1096\n",
      "Epoch 937/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14052.5804 - val_loss: 12657.4459\n",
      "Epoch 938/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 13923.9323 - val_loss: 13260.1057\n",
      "Epoch 939/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 14013.6045 - val_loss: 13729.9309\n",
      "Epoch 940/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13959.4256 - val_loss: 12934.7212\n",
      "Epoch 941/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14320.5392 - val_loss: 13995.1145\n",
      "Epoch 942/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 14821.987 - 1s 402us/step - loss: 14817.3598 - val_loss: 12546.6118\n",
      "Epoch 943/1000\n",
      "2304/2304 [==============================] - 1s 400us/step - loss: 13632.6041 - val_loss: 12900.9206\n",
      "Epoch 944/1000\n",
      "2304/2304 [==============================] - 1s 392us/step - loss: 14375.1462 - val_loss: 12765.3758\n",
      "Epoch 945/1000\n",
      "2304/2304 [==============================] - 1s 378us/step - loss: 14128.5347 - val_loss: 14432.7357\n",
      "Epoch 946/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14197.4131 - val_loss: 13281.8154\n",
      "Epoch 947/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 14080.5850 - val_loss: 12181.3528\n",
      "Epoch 948/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14324.9667 - val_loss: 12349.6915\n",
      "Epoch 949/1000\n",
      "2304/2304 [==============================] - 1s 399us/step - loss: 14012.5511 - val_loss: 13018.6412\n",
      "Epoch 950/1000\n",
      "2304/2304 [==============================] - 1s 390us/step - loss: 14255.0074 - val_loss: 15873.9080\n",
      "Epoch 951/1000\n",
      "2304/2304 [==============================] - 1s 412us/step - loss: 14717.7372 - val_loss: 12762.9510\n",
      "Epoch 952/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13974.3436 - val_loss: 12546.4765\n",
      "Epoch 953/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 14234.0405 - val_loss: 13405.9529\n",
      "Epoch 954/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14021.4645 - val_loss: 12466.7760\n",
      "Epoch 955/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 13925.6977 - val_loss: 13453.8253\n",
      "Epoch 956/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14474.5282 - val_loss: 12504.4543\n",
      "Epoch 957/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 13990.5396 - val_loss: 12301.0943\n",
      "Epoch 958/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 13936.6069 - val_loss: 13217.6736\n",
      "Epoch 959/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 14229.4402 - val_loss: 12295.4087\n",
      "Epoch 960/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 14244.5842 - val_loss: 12878.1249\n",
      "Epoch 961/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 13966.3603 - val_loss: 13099.1012\n",
      "Epoch 962/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14448.5880 - val_loss: 13052.2593\n",
      "Epoch 963/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13804.9836 - val_loss: 13043.3453\n",
      "Epoch 964/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14432.2674 - val_loss: 12421.3675\n",
      "Epoch 965/1000\n",
      "2304/2304 [==============================] - 1s 389us/step - loss: 13866.9203 - val_loss: 12710.0364\n",
      "Epoch 966/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14118.5367 - val_loss: 12608.4325\n",
      "Epoch 967/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13863.9051 - val_loss: 12497.9934\n",
      "Epoch 968/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14055.5219 - val_loss: 12798.6343\n",
      "Epoch 969/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14203.0176 - val_loss: 12626.2237\n",
      "Epoch 970/1000\n",
      "2304/2304 [==============================] - 1s 370us/step - loss: 14280.9816 - val_loss: 12754.1671\n",
      "Epoch 971/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13951.1702 - val_loss: 12712.6477\n",
      "Epoch 972/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14304.2816 - val_loss: 17329.0146\n",
      "Epoch 973/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 15169.8071 - val_loss: 12271.1659\n",
      "Epoch 974/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14481.7509 - val_loss: 13241.9281\n",
      "Epoch 975/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13924.4217 - val_loss: 13457.2602\n",
      "Epoch 976/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 14402.3264 - val_loss: 12988.4250\n",
      "Epoch 977/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13917.5887 - val_loss: 14214.5680\n",
      "Epoch 978/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13851.6644 - val_loss: 14613.6863\n",
      "Epoch 979/1000\n",
      "2304/2304 [==============================] - 1s 375us/step - loss: 13638.6078 - val_loss: 12895.8128\n",
      "Epoch 980/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14048.2012 - val_loss: 15794.4410\n",
      "Epoch 981/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14248.7375 - val_loss: 12595.4897\n",
      "Epoch 982/1000\n",
      "2304/2304 [==============================] - 1s 378us/step - loss: 13976.9222 - val_loss: 12944.9743\n",
      "Epoch 983/1000\n",
      "2304/2304 [==============================] - 1s 380us/step - loss: 13878.1132 - val_loss: 14461.1452\n",
      "Epoch 984/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13750.8418 - val_loss: 13647.0555\n",
      "Epoch 985/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13821.2843 - val_loss: 15657.8466\n",
      "Epoch 986/1000\n",
      "2304/2304 [==============================] - 1s 387us/step - loss: 13951.3668 - val_loss: 12503.4262\n",
      "Epoch 987/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13732.6873 - val_loss: 12674.2793\n",
      "Epoch 988/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14143.0375 - val_loss: 12801.1951\n",
      "Epoch 989/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14586.6882 - val_loss: 13891.1528\n",
      "Epoch 990/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14043.9540 - val_loss: 12848.9969\n",
      "Epoch 991/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14709.4745 - val_loss: 13196.8980\n",
      "Epoch 992/1000\n",
      "2304/2304 [==============================] - 1s 379us/step - loss: 13989.1206 - val_loss: 13358.9111\n",
      "Epoch 993/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13895.6108 - val_loss: 12177.6148\n",
      "Epoch 994/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13983.3783 - val_loss: 12892.7427\n",
      "Epoch 995/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14490.0895 - val_loss: 14749.1190\n",
      "Epoch 996/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14125.6700 - val_loss: 13738.9878\n",
      "Epoch 997/1000\n",
      "2304/2304 [==============================] - 1s 388us/step - loss: 14066.8977 - val_loss: 12453.9828\n",
      "Epoch 998/1000\n",
      "2304/2304 [==============================] - 1s 388us/step - loss: 13551.5174 - val_loss: 14619.2152\n",
      "Epoch 999/1000\n",
      "2304/2304 [==============================] - 1s 386us/step - loss: 13681.4783 - val_loss: 12727.4434\n",
      "Epoch 1000/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14083.6308 - val_loss: 13065.0160\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
